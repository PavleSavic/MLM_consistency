{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1jTqmcujrV08gnyl+HhO6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1cd3814b23f3423c9179f8c0eead1d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0706907be9354d57ad86145a9ccf2e65",
              "IPY_MODEL_bd04b463873e4d4c8120533e68e70fd9",
              "IPY_MODEL_a3591da2678a4d7898651fa9bc2ec2ec"
            ],
            "layout": "IPY_MODEL_8e3fbdf80d794932a2a7585da08ea3ef"
          }
        },
        "0706907be9354d57ad86145a9ccf2e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51e07c77362c4a4a9ece9ace95c99bcb",
            "placeholder": "​",
            "style": "IPY_MODEL_0989215754444591b048d4b561220d80",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "bd04b463873e4d4c8120533e68e70fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c06499d89ec453c8bb2445cdea1afa5",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4381d02b1a644882b974c3764f55c581",
            "value": 48
          }
        },
        "a3591da2678a4d7898651fa9bc2ec2ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06d5865522e84738b2f6b08b38d992c7",
            "placeholder": "​",
            "style": "IPY_MODEL_cbda6c64401246399a345359fd78ae09",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.39kB/s]"
          }
        },
        "8e3fbdf80d794932a2a7585da08ea3ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51e07c77362c4a4a9ece9ace95c99bcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0989215754444591b048d4b561220d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c06499d89ec453c8bb2445cdea1afa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4381d02b1a644882b974c3764f55c581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06d5865522e84738b2f6b08b38d992c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbda6c64401246399a345359fd78ae09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c151f9926834294a1b87bb97ecc2e5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5906b092f44948bebd39e68e787972fb",
              "IPY_MODEL_efdbf0a9cfd849c9a3f378d3fbc89302",
              "IPY_MODEL_5a939ac412454023843fe3b9df77ce74"
            ],
            "layout": "IPY_MODEL_51b1fa6a16e94ef1aded4913634dfc77"
          }
        },
        "5906b092f44948bebd39e68e787972fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d9a3912dba54e79a1ed5cc65aa23090",
            "placeholder": "​",
            "style": "IPY_MODEL_7be858953a524ea7b8fa320570c5f444",
            "value": "config.json: 100%"
          }
        },
        "efdbf0a9cfd849c9a3f378d3fbc89302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d5f9827dcce48e59acfc51b470eaf7b",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe52280088e145f4b460a2e408700770",
            "value": 570
          }
        },
        "5a939ac412454023843fe3b9df77ce74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa463acee622431f89208757d1939c7b",
            "placeholder": "​",
            "style": "IPY_MODEL_c265b2476f51422687310ce7ff0579b5",
            "value": " 570/570 [00:00&lt;00:00, 18.4kB/s]"
          }
        },
        "51b1fa6a16e94ef1aded4913634dfc77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d9a3912dba54e79a1ed5cc65aa23090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7be858953a524ea7b8fa320570c5f444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d5f9827dcce48e59acfc51b470eaf7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe52280088e145f4b460a2e408700770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa463acee622431f89208757d1939c7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c265b2476f51422687310ce7ff0579b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa18400d044c45bdb1ea7f1b39bfb1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d75c909f240246a5b4746b4b59a77686",
              "IPY_MODEL_ec913f1ffb1d4421a590c0b0d1082aed",
              "IPY_MODEL_ef5837bdb1ce48dc9b842b7060f71596"
            ],
            "layout": "IPY_MODEL_2fc2d02f880642e9aa6e9e426d024d74"
          }
        },
        "d75c909f240246a5b4746b4b59a77686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29b8e45d0c3849f4b840da7b4b26c9e6",
            "placeholder": "​",
            "style": "IPY_MODEL_d71b53f6ff93444b86876a9db8e8a7d7",
            "value": "vocab.txt: 100%"
          }
        },
        "ec913f1ffb1d4421a590c0b0d1082aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca98fb5b9afc48ca8ba565d30c60b391",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d8d7803516f488997dabe77669e4da6",
            "value": 231508
          }
        },
        "ef5837bdb1ce48dc9b842b7060f71596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15d94480392f44f19caa6ffdd2d08356",
            "placeholder": "​",
            "style": "IPY_MODEL_c80bb464b6ca4ec984ce0362085fc47e",
            "value": " 232k/232k [00:00&lt;00:00, 5.04MB/s]"
          }
        },
        "2fc2d02f880642e9aa6e9e426d024d74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29b8e45d0c3849f4b840da7b4b26c9e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d71b53f6ff93444b86876a9db8e8a7d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca98fb5b9afc48ca8ba565d30c60b391": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d8d7803516f488997dabe77669e4da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15d94480392f44f19caa6ffdd2d08356": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c80bb464b6ca4ec984ce0362085fc47e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a6497331344455a8986ac24d9f190c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d57bf234ce07406e9d2a93c8cf41fbfa",
              "IPY_MODEL_fa4a6966bf734bb694b81bcbab69ea5b",
              "IPY_MODEL_c6442ab1e4434c358eca29a484e3060d"
            ],
            "layout": "IPY_MODEL_3facdc6cfe8b4ff39aa66ac5551dcfaa"
          }
        },
        "d57bf234ce07406e9d2a93c8cf41fbfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adeaf67d905c421596acf96fd169b889",
            "placeholder": "​",
            "style": "IPY_MODEL_cdcdf2ac197a4766a793c4fce82dde3f",
            "value": "tokenizer.json: 100%"
          }
        },
        "fa4a6966bf734bb694b81bcbab69ea5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bce0ad1a816e4b0fbda4e683975dc644",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b94d00dbc37437496d5016122294faf",
            "value": 466062
          }
        },
        "c6442ab1e4434c358eca29a484e3060d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_701a716e5f094642aa694a5e82875b68",
            "placeholder": "​",
            "style": "IPY_MODEL_1fe37b347c554d9aa7e50099816cf4a7",
            "value": " 466k/466k [00:00&lt;00:00, 10.3MB/s]"
          }
        },
        "3facdc6cfe8b4ff39aa66ac5551dcfaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adeaf67d905c421596acf96fd169b889": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdcdf2ac197a4766a793c4fce82dde3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bce0ad1a816e4b0fbda4e683975dc644": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b94d00dbc37437496d5016122294faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "701a716e5f094642aa694a5e82875b68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fe37b347c554d9aa7e50099816cf4a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec4b4f8d98294e2ea6a71b14b99d2b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23c2adf3a6204af6a22400c74f97a1e2",
              "IPY_MODEL_47a45a0d72994ee29dc9a68fa50b83e3",
              "IPY_MODEL_3812dcdbfada489eae4eca89f7b18148"
            ],
            "layout": "IPY_MODEL_487dc6b8520041b8a29bb1fecf0406a9"
          }
        },
        "23c2adf3a6204af6a22400c74f97a1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04f6b12fbf324ee1b2b05f8218adc1e2",
            "placeholder": "​",
            "style": "IPY_MODEL_598d9070bdca43f0a3b0e92af8f063c2",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "47a45a0d72994ee29dc9a68fa50b83e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a44a96d4ab5b43d387ca0ecb4fa1241d",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2585d6b75e44611a59b6948cfac5b38",
            "value": 440473133
          }
        },
        "3812dcdbfada489eae4eca89f7b18148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_459f805e44694ccba0eaa83f3fa65a39",
            "placeholder": "​",
            "style": "IPY_MODEL_7d6509c4fb16453d89621b1c9d98d7aa",
            "value": " 440M/440M [00:03&lt;00:00, 164MB/s]"
          }
        },
        "487dc6b8520041b8a29bb1fecf0406a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04f6b12fbf324ee1b2b05f8218adc1e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "598d9070bdca43f0a3b0e92af8f063c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a44a96d4ab5b43d387ca0ecb4fa1241d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2585d6b75e44611a59b6948cfac5b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "459f805e44694ccba0eaa83f3fa65a39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d6509c4fb16453d89621b1c9d98d7aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PavleSavic/MLM_consistency/blob/main/consistency_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тhis notebook presents the final versions of the functions required for testing model accuracy and consistency, as well as the actual testing of the mentioned measures on some of the relations from the datаset. In the final part of the notebook, a method for fine-tuning the model with the aim of increasing consistency is presented."
      ],
      "metadata": {
        "id": "hQyPGZ2Xc8aH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mUJcYHRF4-Hc"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import string\n",
        "import logging\n",
        "import heapq\n",
        "from typing import Callable\n",
        "from collections import OrderedDict\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "#!pip install transformers datasets evaluate\n",
        "from transformers import AutoTokenizer, TFAutoModelForMaskedLM, TFAutoModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(123)\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.ERROR)"
      ],
      "metadata": {
        "id": "TqFXWSWMjkFA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cbf80f8-f8be-43b1-b03c-fd728f0d5632"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
            "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
            "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyzed models"
      ],
      "metadata": {
        "id": "ilYNV_2qDyuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uncased\n",
        "bert_models = {'BERT_base' : \"google-bert/bert-base-uncased\", 'BERT_large': \"google-bert/bert-large-uncased\",\n",
        "                'BERT_large_wwm': \"google-bert/bert-large-uncased-whole-word-masking\"}\n",
        "# cased\n",
        "roberta_models = {'RoBERTa_base': \"FacebookAI/roberta-base\", 'RoBERTa_large': \"FacebookAI/roberta-large\"}\n",
        "# uncased\n",
        "albert_models = {'ALBERT_base': \"albert/albert-base-v2\", 'ALBERT_xxlarge': \"albert/albert-xxlarge-v2\"}\n",
        "# cased\n",
        "biobert_models = {'BioBERT': \"dmis-lab/biobert-base-cased-v1.2\"}\n",
        "# uncased\n",
        "biomedbert_models = {'BioMedBERT_base_abstract' : \"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract\",\n",
        "                     'BioMedBERT_base_full': \"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\",\n",
        "                     'BioMedBERT_large_abstract': \"microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract\"}"
      ],
      "metadata": {
        "id": "d5_5Zlu2Duob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proposed functions for making multi-token predictions - Conditional MLM"
      ],
      "metadata": {
        "id": "7dAHashHkmv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def change_input_format(input):\n",
        "  new_input = input.replace('[MASK]','<mask>')\n",
        "  return new_input"
      ],
      "metadata": {
        "id": "tgg_B5WalhPe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_masks(text:str, num_masks_to_keep: int, mask_str='[MASK]'):\n",
        "    parts = text.split('[MASK]')\n",
        "    num_masks = len(parts) - 1\n",
        "\n",
        "    if num_masks_to_keep > num_masks:\n",
        "        raise ValueError(f\"The text only contains {num_masks} '[MASK]' tokens, but {num_masks_to_keep} were requested to keep!\")\n",
        "\n",
        "    reduced_text = ' [MASK]'.join(part.strip() for part in parts[:num_masks_to_keep + 1])\n",
        "    remaining_text = ''.join(parts[num_masks_to_keep + 1:]).strip()\n",
        "\n",
        "    if remaining_text:\n",
        "        reduced_text += ' ' + remaining_text\n",
        "\n",
        "    return reduced_text.strip()"
      ],
      "metadata": {
        "id": "JhDTSjLLmwKx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conditional MLM\n",
        "# filling masks in parallel independently (Independent approach)\n",
        "# trying different mask token sequence lengths\n",
        "def fill_masks_independently(model_checkpoint: str, inputs: list[str], candidate_set_tokens=None, verbose=0):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "    model = TFAutoModelForMaskedLM.from_pretrained(model_checkpoint, from_pt=True)\n",
        "\n",
        "    mask_str = '[MASK]'\n",
        "    # Adjusting inputs for RoBERTa models\n",
        "    if 'roberta' in model_checkpoint:\n",
        "        mask_str = '<mask>'\n",
        "        inputs = [change_input_format(input) for input in inputs]\n",
        "\n",
        "    # model_max_length field not set by default for BioBERT and BioMedBERT models\n",
        "    if 'bio' in model_checkpoint.lower():\n",
        "        tokenizer.model_max_length = 512\n",
        "\n",
        "    if verbose:\n",
        "        print(f'Chosen model: {model_checkpoint}')\n",
        "        model.summary()\n",
        "\n",
        "    # if candidate_set_tokens is None, setting it to all tokens of the model\n",
        "    if candidate_set_tokens is None:\n",
        "      candidate_set_tokens = list(tokenizer.get_vocab().values()) # .keys() - decoded tokens (words/subwords)\n",
        "\n",
        "    outputs = []\n",
        "    outputs_decoded = []\n",
        "\n",
        "    for input in inputs:\n",
        "      # trying different mask token sequence lengths - from 1 to M (length of longest true answer)\n",
        "      M = input.count(mask_str)\n",
        "\n",
        "      max_confidence = 0\n",
        "      most_confident_prediction = None\n",
        "\n",
        "      for i in range(1, M+1):\n",
        "\n",
        "        input_text = reduce_masks(input, i, mask_str)\n",
        "        tokenized_input = tokenizer(input_text, return_tensors=\"tf\")\n",
        "\n",
        "        # checking if the model uses token_type_ids (not used in RoBERTa models)\n",
        "        use_token_type_ids = 'token_type_ids' in tokenized_input\n",
        "\n",
        "        # getting the token logits from the model\n",
        "        token_logits = model(**tokenized_input).logits[0]\n",
        "\n",
        "        token_probs = tf.nn.softmax(token_logits, axis=-1)\n",
        "\n",
        "        input_ids = tokenized_input[\"input_ids\"]\n",
        "\n",
        "        mask_token_indices = np.where(input_ids.numpy()[0] == tokenizer.mask_token_id)[0]\n",
        "\n",
        "        mask_token_probs = tf.gather(token_probs, mask_token_indices)\n",
        "\n",
        "        # getting probs of tokens that are present in a candidate set\n",
        "        mask_token_probs_candidates = tf.gather(mask_token_probs, candidate_set_tokens, axis=1)\n",
        "\n",
        "        # tf.matf.top_k returns k top values and indices from the input tensor along last dimension (by default)\n",
        "        top_values, top_indices  = tf.math.top_k(mask_token_probs_candidates, k=1)\n",
        "\n",
        "        # finding original indices (token ids):\n",
        "        # converting candidate_set_tokens to a tf tensor\n",
        "        candidate_set_tokens_tensor = tf.constant(candidate_set_tokens, dtype=tf.int32)\n",
        "        # using tf.gather to transform the indices to corresponding values from candidate_set_tokens_tensor\n",
        "        top_indices_original = tf.gather(candidate_set_tokens_tensor, top_indices)\n",
        "\n",
        "        # confidence - probs of the predicted tokens / number of predicted tokens\n",
        "        confidence = np.sum(tf.squeeze(top_values).numpy()) / len(mask_token_indices)\n",
        "        prediction = list(np.atleast_1d(tf.squeeze(top_indices_original).numpy()))\n",
        "\n",
        "        if verbose:\n",
        "          print(f'Prediction: {prediction} : {tokenizer.convert_ids_to_tokens(prediction)}')\n",
        "          print(f'Confidence: {confidence}')\n",
        "\n",
        "        if confidence > max_confidence:\n",
        "          max_confidence = confidence\n",
        "          most_confident_prediction = prediction\n",
        "\n",
        "      outputs.append(most_confident_prediction)\n",
        "      prediction_decoded = tokenizer.decode(most_confident_prediction, skip_special_tokens=True)\n",
        "      outputs_decoded.append(prediction_decoded)\n",
        "      if verbose:\n",
        "        print('-----------------------------------------------------------------------------------')\n",
        "\n",
        "    return outputs, outputs_decoded"
      ],
      "metadata": {
        "id": "xEfT8zRRjrau"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_inputs = [\"Paris is a [MASK] [MASK] to visit.\", \"Jupyter is the largest planet of the [MASK] [MASK].\", \"The weather forecast predicts [MASK] [MASK] for tomorrow.\", \"The weather forecast predicts heavy rain and [MASK] [MASK].\", \"He wanted to visit the museum and explore the [MASK] [MASK].\", \"She was excited about the promotion and [MASK] [MASK].\", \"He is known for his dedication and [MASK] [MASK] [MASK].\", \"They plan to travel to Italy and enjoy the beautiful [MASK] [MASK] [MASK].\",  \"She decided to go to the market and buy some fresh [MASK] [MASK] [MASK] [MASK].\", \"He set a new world record at the [MASK] [MASK] [MASK] [MASK] event.\"]\n",
        "outputs, outputs_dec = fill_masks_independently(bert_models['BERT_base'], test_inputs, verbose=1)\n",
        "\n",
        "test_tokenizer = AutoTokenizer.from_pretrained(bert_models['BERT_base'])\n",
        "\n",
        "i = 0\n",
        "for output, output_dec in zip(outputs, outputs_dec):\n",
        "  print(test_inputs[i])\n",
        "  print(f\"{output} : {output_dec} : {test_tokenizer.convert_ids_to_tokens(output)}\")\n",
        "  i += 1\n",
        "  print('-------------------------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1cd3814b23f3423c9179f8c0eead1d5a",
            "0706907be9354d57ad86145a9ccf2e65",
            "bd04b463873e4d4c8120533e68e70fd9",
            "a3591da2678a4d7898651fa9bc2ec2ec",
            "8e3fbdf80d794932a2a7585da08ea3ef",
            "51e07c77362c4a4a9ece9ace95c99bcb",
            "0989215754444591b048d4b561220d80",
            "9c06499d89ec453c8bb2445cdea1afa5",
            "4381d02b1a644882b974c3764f55c581",
            "06d5865522e84738b2f6b08b38d992c7",
            "cbda6c64401246399a345359fd78ae09",
            "7c151f9926834294a1b87bb97ecc2e5c",
            "5906b092f44948bebd39e68e787972fb",
            "efdbf0a9cfd849c9a3f378d3fbc89302",
            "5a939ac412454023843fe3b9df77ce74",
            "51b1fa6a16e94ef1aded4913634dfc77",
            "7d9a3912dba54e79a1ed5cc65aa23090",
            "7be858953a524ea7b8fa320570c5f444",
            "5d5f9827dcce48e59acfc51b470eaf7b",
            "fe52280088e145f4b460a2e408700770",
            "fa463acee622431f89208757d1939c7b",
            "c265b2476f51422687310ce7ff0579b5",
            "aa18400d044c45bdb1ea7f1b39bfb1a7",
            "d75c909f240246a5b4746b4b59a77686",
            "ec913f1ffb1d4421a590c0b0d1082aed",
            "ef5837bdb1ce48dc9b842b7060f71596",
            "2fc2d02f880642e9aa6e9e426d024d74",
            "29b8e45d0c3849f4b840da7b4b26c9e6",
            "d71b53f6ff93444b86876a9db8e8a7d7",
            "ca98fb5b9afc48ca8ba565d30c60b391",
            "1d8d7803516f488997dabe77669e4da6",
            "15d94480392f44f19caa6ffdd2d08356",
            "c80bb464b6ca4ec984ce0362085fc47e",
            "2a6497331344455a8986ac24d9f190c6",
            "d57bf234ce07406e9d2a93c8cf41fbfa",
            "fa4a6966bf734bb694b81bcbab69ea5b",
            "c6442ab1e4434c358eca29a484e3060d",
            "3facdc6cfe8b4ff39aa66ac5551dcfaa",
            "adeaf67d905c421596acf96fd169b889",
            "cdcdf2ac197a4766a793c4fce82dde3f",
            "bce0ad1a816e4b0fbda4e683975dc644",
            "9b94d00dbc37437496d5016122294faf",
            "701a716e5f094642aa694a5e82875b68",
            "1fe37b347c554d9aa7e50099816cf4a7",
            "ec4b4f8d98294e2ea6a71b14b99d2b6a",
            "23c2adf3a6204af6a22400c74f97a1e2",
            "47a45a0d72994ee29dc9a68fa50b83e3",
            "3812dcdbfada489eae4eca89f7b18148",
            "487dc6b8520041b8a29bb1fecf0406a9",
            "04f6b12fbf324ee1b2b05f8218adc1e2",
            "598d9070bdca43f0a3b0e92af8f063c2",
            "a44a96d4ab5b43d387ca0ecb4fa1241d",
            "c2585d6b75e44611a59b6948cfac5b38",
            "459f805e44694ccba0eaa83f3fa65a39",
            "7d6509c4fb16453d89621b1c9d98d7aa"
          ]
        },
        "id": "tFb51a56vUIU",
        "outputId": "44b99b14-24e2-4bcd-ea70-dfc90c754c2b",
        "collapsed": true
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cd3814b23f3423c9179f8c0eead1d5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c151f9926834294a1b87bb97ecc2e5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa18400d044c45bdb1ea7f1b39bfb1a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a6497331344455a8986ac24d9f190c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec4b4f8d98294e2ea6a71b14b99d2b6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen model: google-bert/bert-base-uncased\n",
            "Model: \"tf_bert_for_masked_lm\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  108891648 \n",
            "                                                                 \n",
            " mlm___cls (TFBertMLMHead)   multiple                  24459834  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109514298 (417.76 MB)\n",
            "Trainable params: 109514298 (417.76 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Prediction: [2173] : ['place']\n",
            "Confidence: 0.7230950593948364\n",
            "Prediction: [2307, 2173] : ['great', 'place']\n",
            "Confidence: 0.5290212631225586\n",
            "-----------------------------------------------------------------------------------\n",
            "Prediction: [3103] : ['sun']\n",
            "Confidence: 0.20109564065933228\n",
            "Prediction: [3103, 2155] : ['sun', 'family']\n",
            "Confidence: 0.2359308898448944\n",
            "-----------------------------------------------------------------------------------\n",
            "Prediction: [4633] : ['weather']\n",
            "Confidence: 0.3794039189815521\n",
            "Prediction: [1996, 4633] : ['the', 'weather']\n",
            "Confidence: 0.46575427055358887\n",
            "-----------------------------------------------------------------------------------\n",
            "Prediction: [4586] : ['snow']\n",
            "Confidence: 0.483038067817688\n",
            "Prediction: [4586, 7266] : ['snow', 'winds']\n",
            "Confidence: 0.19853292405605316\n",
            "-----------------------------------------------------------------------------------\n",
            "Prediction: [2103] : ['city']\n",
            "Confidence: 0.13459141552448273\n",
            "Prediction: [2334, 2088] : ['local', 'world']\n",
            "Confidence: 0.07630414515733719\n",
            "-----------------------------------------------------------------------------------\n",
            "Prediction: [4712] : ['promotion']\n",
            "Confidence: 0.11541903018951416\n",
            "Prediction: [1996, 2769] : ['the', 'money']\n",
            "Confidence: 0.15952114760875702\n",
            "-----------------------------------------------------------------------------------\n",
            "Prediction: [12276] : ['dedication']\n",
            "Confidence: 0.18447323143482208\n",
            "Prediction: [3167, 9128] : ['personal', 'determination']\n",
            "Confidence: 0.08673734217882156\n",
            "Prediction: [2010, 3167, 3241] : ['his', 'personal', 'thinking']\n",
            "Confidence: 0.06939616799354553\n",
            "-----------------------------------------------------------------------------------\n",
            "Prediction: [17363] : ['scenery']\n",
            "Confidence: 0.27261894941329956\n",
            "Prediction: [3059, 10833] : ['italian', 'countryside']\n",
            "Confidence: 0.3146092891693115\n",
            "Prediction: [3059, 3059, 10833] : ['italian', 'italian', 'countryside']\n",
            "Confidence: 0.18573009967803955\n",
            "-----------------------------------------------------------------------------------\n",
            "Prediction: [4253] : ['clothes']\n",
            "Confidence: 0.20658248662948608\n",
            "Prediction: [5909, 7852] : ['fruit', 'bread']\n",
            "Confidence: 0.08682030439376831\n",
            "Prediction: [1010, 1998, 7852] : [',', 'and', 'bread']\n",
            "Confidence: 0.1390327513217926\n",
            "Prediction: [11546, 1998, 2000, 2014] : ['vegetables', 'and', 'to', 'her']\n",
            "Confidence: 0.1413540542125702\n",
            "-----------------------------------------------------------------------------------\n",
            "Prediction: [2168] : ['same']\n",
            "Confidence: 0.871084451675415\n",
            "Prediction: [2168, 2168] : ['same', 'same']\n",
            "Confidence: 0.753655195236206\n",
            "Prediction: [2230, 4386, 3783] : ['2010', 'olympic', 'olympics']\n",
            "Confidence: 0.06973844269911449\n",
            "Prediction: [2286, 2088, 2399, 2399] : ['2013', 'world', 'games', 'games']\n",
            "Confidence: 0.10273277014493942\n",
            "-----------------------------------------------------------------------------------\n",
            "Paris is a [MASK] [MASK] to visit.\n",
            "[2173] : place : ['place']\n",
            "-------------------------------------------------------------------------\n",
            "Jupyter is the largest planet of the [MASK] [MASK].\n",
            "[3103, 2155] : sun family : ['sun', 'family']\n",
            "-------------------------------------------------------------------------\n",
            "The weather forecast predicts [MASK] [MASK] for tomorrow.\n",
            "[1996, 4633] : the weather : ['the', 'weather']\n",
            "-------------------------------------------------------------------------\n",
            "The weather forecast predicts heavy rain and [MASK] [MASK].\n",
            "[4586] : snow : ['snow']\n",
            "-------------------------------------------------------------------------\n",
            "He wanted to visit the museum and explore the [MASK] [MASK].\n",
            "[2103] : city : ['city']\n",
            "-------------------------------------------------------------------------\n",
            "She was excited about the promotion and [MASK] [MASK].\n",
            "[1996, 2769] : the money : ['the', 'money']\n",
            "-------------------------------------------------------------------------\n",
            "He is known for his dedication and [MASK] [MASK] [MASK].\n",
            "[12276] : dedication : ['dedication']\n",
            "-------------------------------------------------------------------------\n",
            "They plan to travel to Italy and enjoy the beautiful [MASK] [MASK] [MASK].\n",
            "[3059, 10833] : italian countryside : ['italian', 'countryside']\n",
            "-------------------------------------------------------------------------\n",
            "She decided to go to the market and buy some fresh [MASK] [MASK] [MASK] [MASK].\n",
            "[4253] : clothes : ['clothes']\n",
            "-------------------------------------------------------------------------\n",
            "He set a new world record at the [MASK] [MASK] [MASK] [MASK] event.\n",
            "[2168] : same : ['same']\n",
            "-------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conditional MLM\n",
        "# filling masks autoregressively (Order approach - left to right)\n",
        "# trying different mask token sequence lengths\n",
        "def fill_masks_autoregressively(model_checkpoint: str, inputs: list[str], candidate_set_tokens=None, verbose=0):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "    model = TFAutoModelForMaskedLM.from_pretrained(model_checkpoint, from_pt=True)\n",
        "\n",
        "    mask_str = '[MASK]'\n",
        "    # Adjusting inputs for RoBERTa models\n",
        "    if 'roberta' in model_checkpoint:\n",
        "        inputs = [change_input_format(input) for input in inputs]\n",
        "        mask_str = '<mask>'\n",
        "\n",
        "    # model_max_length field not set by default for BioBERT and BioMedBERT models\n",
        "    if 'bio' in model_checkpoint.lower():\n",
        "        tokenizer.model_max_length = 512\n",
        "\n",
        "    if verbose:\n",
        "        print(f'Chosen model: {model_checkpoint}')\n",
        "        model.summary()\n",
        "\n",
        "    # if candidate_set_tokens is None, setting it to all tokens of the model\n",
        "    if candidate_set_tokens is None:\n",
        "      candidate_set_tokens = list(tokenizer.get_vocab().values()) # .keys() - decoded tokens (words/subwords)\n",
        "\n",
        "    outputs = []\n",
        "    outputs_decoded = []\n",
        "\n",
        "    for input in inputs:\n",
        "      # trying different mask token sequence lengths - from 1 to M (length of longest true answer)\n",
        "      M = input.count(mask_str)\n",
        "\n",
        "      max_confidence = 0\n",
        "      most_confident_prediction = None\n",
        "\n",
        "      for i in range(1, M+1):\n",
        "\n",
        "        input_text = reduce_masks(input, i, mask_str)\n",
        "\n",
        "        tokenized_input = tokenizer(input_text, return_tensors=\"tf\")\n",
        "\n",
        "        # checking if the model uses token_type_ids (not used in RoBERTa models)\n",
        "        use_token_type_ids = 'token_type_ids' in tokenized_input\n",
        "\n",
        "        input_ids = tokenized_input[\"input_ids\"]\n",
        "\n",
        "        # finding all positions of the mask tokens\n",
        "        mask_token_indices = np.where(input_ids.numpy()[0] == tokenizer.mask_token_id)[0]\n",
        "\n",
        "        # not necessary to be computed\n",
        "        if verbose:\n",
        "          initial_confidence = 0\n",
        "\n",
        "        prediction = []\n",
        "        for mask_index in mask_token_indices:\n",
        "\n",
        "          token_logits = model(**tokenized_input).logits[0]\n",
        "          token_probs = tf.nn.softmax(token_logits, axis=-1)\n",
        "          mask_token_probs = token_probs[mask_index, :]\n",
        "\n",
        "          # getting the top predicted token from candidate set\n",
        "          top_token = candidate_set_tokens[np.argmax(mask_token_probs.numpy()[candidate_set_tokens])]\n",
        "\n",
        "          if verbose:\n",
        "            initial_confidence += mask_token_probs.numpy()[top_token]\n",
        "\n",
        "          prediction.append(top_token)\n",
        "                                                            # list of tensor coordinates to change\n",
        "          input_ids = tf.tensor_scatter_nd_update(input_ids, [[0, mask_index]], [top_token])\n",
        "\n",
        "          # making new tokenized_input tensor\n",
        "          if use_token_type_ids:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "              'token_type_ids': tokenized_input['token_type_ids']\n",
        "            }\n",
        "          else:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "            }\n",
        "\n",
        "        if verbose:\n",
        "          initial_confidence /= i\n",
        "          print(f'Prediction: {prediction} : {tokenizer.convert_ids_to_tokens(prediction)}')\n",
        "          print(f'Confidence before recomputing: {initial_confidence}')\n",
        "\n",
        "        # recompute confidence of every predicted token (this provides the probability of each token in the context of the entire sequence -  bidirectional conditional distributions)\n",
        "        confidence = 0\n",
        "        for mask_index in mask_token_indices:\n",
        "          predicted_token = tf.gather_nd(input_ids, [[0, mask_index]])[0]\n",
        "\n",
        "          # replacing predicted token with mask to remove bias\n",
        "          input_ids = tf.tensor_scatter_nd_update(input_ids, [[0, mask_index]], [tokenizer.mask_token_id])\n",
        "\n",
        "          if use_token_type_ids:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "              'token_type_ids': tokenized_input['token_type_ids']\n",
        "            }\n",
        "          else:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "            }\n",
        "\n",
        "          token_logits = model(**tokenized_input).logits[0]\n",
        "          token_probs = tf.nn.softmax(token_logits, axis=-1)\n",
        "          mask_token_probs = token_probs[mask_index, :]\n",
        "          # getting prob of predicted token in the context of the entire predicted sequence\n",
        "          confidence += mask_token_probs.numpy()[predicted_token]\n",
        "\n",
        "          # putting predicted token back to the context\n",
        "          input_ids = tf.tensor_scatter_nd_update(input_ids, [[0, mask_index]], [predicted_token])\n",
        "\n",
        "          if use_token_type_ids:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "              'token_type_ids': tokenized_input['token_type_ids']\n",
        "            }\n",
        "          else:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "            }\n",
        "\n",
        "        confidence /= i\n",
        "        if verbose:\n",
        "          print(f'Confidence after recomputing: {confidence}')\n",
        "\n",
        "        if confidence > max_confidence:\n",
        "          max_confidence = confidence\n",
        "          most_confident_prediction = prediction\n",
        "\n",
        "      outputs.append(most_confident_prediction)\n",
        "      prediction_decoded = tokenizer.decode(most_confident_prediction, skip_special_tokens=True)\n",
        "      outputs_decoded.append(prediction_decoded)\n",
        "      if verbose:\n",
        "        print('-----------------------------------------------------------------------------------')\n",
        "\n",
        "    return outputs, outputs_decoded"
      ],
      "metadata": {
        "id": "xyKrDO5PDH6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs, outputs_dec = fill_masks_autoregressively(bert_models['BERT_base'], test_inputs, verbose=1)\n",
        "\n",
        "test_tokenizer = AutoTokenizer.from_pretrained(bert_models['BERT_base'])\n",
        "\n",
        "i = 0\n",
        "for output, output_dec in zip(outputs, outputs_dec):\n",
        "  print(test_inputs[i])\n",
        "  print(f\"{output} : {output_dec} : {test_tokenizer.convert_ids_to_tokens(output)}\")\n",
        "  i += 1\n",
        "  print('-------------------------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVmYJX-lcvxs",
        "outputId": "b0604468-06a3-48be-cc26-67802bc760a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen model: google-bert/bert-base-uncased\n",
            "Model: \"tf_bert_for_masked_lm_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  108891648 \n",
            "                                                                 \n",
            " mlm___cls (TFBertMLMHead)   multiple                  24459834  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109514298 (417.76 MB)\n",
            "Trainable params: 109514298 (417.76 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Prediction: [2173] : ['place']\n",
            "Confidence before recomputing: 0.7230950593948364\n",
            "Confidence after recomputing: 0.7230950593948364\n",
            "Prediction: [2307, 2173] : ['great', 'place']\n",
            "Confidence before recomputing: 0.5600524544715881\n",
            "Confidence after recomputing: 0.6126892864704132\n",
            "-----------------------------------------------------------------------------------\n",
            "Prediction: [3103] : ['sun']\n",
            "Confidence before recomputing: 0.20109564065933228\n",
            "Confidence after recomputing: 0.20109564065933228\n",
            "Prediction: [3103, 2291] : ['sun', 'system']\n",
            "Confidence before recomputing: 0.3070455491542816\n",
            "Confidence after recomputing: 0.17841963648970705\n",
            "-----------------------------------------------------------------------------------\n",
            "Prediction: [4633] : ['weather']\n",
            "Confidence before recomputing: 0.3794039189815521\n",
            "Confidence after recomputing: 0.3794039189815521\n",
            "Prediction: [1996, 4633] : ['the', 'weather']\n",
            "Confidence before recomputing: 0.5253995656967163\n",
            "Confidence after recomputing: 0.8356338739395142\n",
            "-----------------------------------------------------------------------------------\n",
            "Prediction: [4586] : ['snow']\n",
            "Confidence before recomputing: 0.483038067817688\n",
            "Confidence after recomputing: 0.483038067817688\n",
            "Prediction: [4586, 3785] : ['snow', 'conditions']\n",
            "Confidence before recomputing: 0.18335624039173126\n",
            "Confidence after recomputing: 0.1136405635625124\n",
            "-----------------------------------------------------------------------------------\n",
            "Prediction: [2103] : ['city']\n",
            "Confidence before recomputing: 0.13459141552448273\n",
            "Confidence after recomputing: 0.13459141552448273\n",
            "Prediction: [2334, 2381] : ['local', 'history']\n",
            "Confidence before recomputing: 0.2138642519712448\n",
            "Confidence after recomputing: 0.567966639995575\n",
            "-----------------------------------------------------------------------------------\n",
            "Prediction: [4712] : ['promotion']\n",
            "Confidence before recomputing: 0.11541903018951416\n",
            "Confidence after recomputing: 0.11541903018951416\n",
            "Prediction: [1996, 3105] : ['the', 'job']\n",
            "Confidence before recomputing: 0.18584313616156578\n",
            "Confidence after recomputing: 0.3171945624053478\n",
            "-----------------------------------------------------------------------------------\n",
            "Prediction: [12276] : ['dedication']\n",
            "Confidence before recomputing: 0.18447323143482208\n",
            "Confidence after recomputing: 0.18447323143482208\n",
            "Prediction: [3167, 12276] : ['personal', 'dedication']\n",
            "Confidence before recomputing: 0.0920996367931366\n",
            "Confidence after recomputing: 0.14569056034088135\n",
            "Prediction: [2010, 5541, 2943] : ['his', 'creative', 'energy']\n",
            "Confidence before recomputing: 0.0721778894464175\n",
            "Confidence after recomputing: 0.2102151041229566\n",
            "-----------------------------------------------------------------------------------\n",
            "Prediction: [17363] : ['scenery']\n",
            "Confidence before recomputing: 0.27261894941329956\n",
            "Confidence after recomputing: 0.27261894941329956\n",
            "Prediction: [3059, 10833] : ['italian', 'countryside']\n",
            "Confidence before recomputing: 0.40707463026046753\n",
            "Confidence after recomputing: 0.6007926762104034\n",
            "Prediction: [3059, 2406, 17363] : ['italian', 'country', 'scenery']\n",
            "Confidence before recomputing: 0.14479599396387735\n",
            "Confidence after recomputing: 0.32345331211884815\n",
            "-----------------------------------------------------------------------------------\n",
            "Prediction: [4253] : ['clothes']\n",
            "Confidence before recomputing: 0.20658248662948608\n",
            "Confidence after recomputing: 0.20658248662948608\n",
            "Prediction: [5909, 2612] : ['fruit', 'instead']\n",
            "Confidence before recomputing: 0.2653672359883785\n",
            "Confidence after recomputing: 0.2714965157210827\n",
            "Prediction: [1010, 4840, 4253] : [',', 'fresh', 'clothes']\n",
            "Confidence before recomputing: 0.321824053923289\n",
            "Confidence after recomputing: 0.49307260289788246\n",
            "Prediction: [11546, 2005, 1996, 2154] : ['vegetables', 'for', 'the', 'day']\n",
            "Confidence before recomputing: 0.38971314392983913\n",
            "Confidence after recomputing: 0.6266731545329094\n",
            "-----------------------------------------------------------------------------------\n",
            "Prediction: [2168] : ['same']\n",
            "Confidence before recomputing: 0.871084451675415\n",
            "Confidence after recomputing: 0.871084451675415\n",
            "Prediction: [2168, 2168] : ['same', 'same']\n",
            "Confidence before recomputing: 0.4657422564923763\n",
            "Confidence after recomputing: 0.10493944957852364\n",
            "Prediction: [2230, 4386, 6042] : ['2010', 'olympic', 'qualifying']\n",
            "Confidence before recomputing: 0.15121306975682577\n",
            "Confidence after recomputing: 0.4237557364006837\n",
            "Prediction: [2286, 2621, 3783, 6042] : ['2013', 'summer', 'olympics', 'qualifying']\n",
            "Confidence before recomputing: 0.35553621873259544\n",
            "Confidence after recomputing: 0.34045373071421636\n",
            "-----------------------------------------------------------------------------------\n",
            "Paris is a [MASK] [MASK] to visit.\n",
            "[2173] : place : ['place']\n",
            "-------------------------------------------------------------------------\n",
            "Jupyter is the largest planet of the [MASK] [MASK].\n",
            "[3103] : sun : ['sun']\n",
            "-------------------------------------------------------------------------\n",
            "The weather forecast predicts [MASK] [MASK] for tomorrow.\n",
            "[1996, 4633] : the weather : ['the', 'weather']\n",
            "-------------------------------------------------------------------------\n",
            "The weather forecast predicts heavy rain and [MASK] [MASK].\n",
            "[4586] : snow : ['snow']\n",
            "-------------------------------------------------------------------------\n",
            "He wanted to visit the museum and explore the [MASK] [MASK].\n",
            "[2334, 2381] : local history : ['local', 'history']\n",
            "-------------------------------------------------------------------------\n",
            "She was excited about the promotion and [MASK] [MASK].\n",
            "[1996, 3105] : the job : ['the', 'job']\n",
            "-------------------------------------------------------------------------\n",
            "He is known for his dedication and [MASK] [MASK] [MASK].\n",
            "[2010, 5541, 2943] : his creative energy : ['his', 'creative', 'energy']\n",
            "-------------------------------------------------------------------------\n",
            "They plan to travel to Italy and enjoy the beautiful [MASK] [MASK] [MASK].\n",
            "[3059, 10833] : italian countryside : ['italian', 'countryside']\n",
            "-------------------------------------------------------------------------\n",
            "She decided to go to the market and buy some fresh [MASK] [MASK] [MASK] [MASK].\n",
            "[11546, 2005, 1996, 2154] : vegetables for the day : ['vegetables', 'for', 'the', 'day']\n",
            "-------------------------------------------------------------------------\n",
            "He set a new world record at the [MASK] [MASK] [MASK] [MASK] event.\n",
            "[2168] : same : ['same']\n",
            "-------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conditional MLM\n",
        "# filling masks sorted by the maximum confidence (Greedy approach)\n",
        "# trying different mask token sequence lengths\n",
        "def fill_masks_by_confidence(model_checkpoint: str, inputs: list[str], candidate_set_tokens=None, verbose=0):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "    model = TFAutoModelForMaskedLM.from_pretrained(model_checkpoint, from_pt=True)\n",
        "\n",
        "    mask_str = '[MASK]'\n",
        "    # Adjusting inputs for RoBERTa models\n",
        "    if 'roberta' in model_checkpoint:\n",
        "      mask_str = '<mask>'\n",
        "      inputs = [change_input_format(input) for input in inputs]\n",
        "\n",
        "    # model_max_length field not set by default for BioBERT and BioMedBERT models\n",
        "    if 'bio' in model_checkpoint.lower():\n",
        "      tokenizer.model_max_length = 512\n",
        "\n",
        "    if verbose:\n",
        "      print(f'Chosen model: {model_checkpoint}')\n",
        "      model.summary()\n",
        "\n",
        "    # if candidate_set_tokens is None, setting it to all tokens of the model\n",
        "    if candidate_set_tokens is None:\n",
        "      candidate_set_tokens = list(tokenizer.get_vocab().values()) # .keys() - decoded tokens (words/subwords)\n",
        "\n",
        "    outputs = []\n",
        "    outputs_decoded = []\n",
        "\n",
        "    for input in inputs:\n",
        "      # trying different mask token sequence lengths - from 1 to M (length of longest true answer)\n",
        "      M = input.count(mask_str)\n",
        "\n",
        "      max_confidence = 0\n",
        "      most_confident_prediction = None\n",
        "\n",
        "      for i in range(1, M+1):\n",
        "\n",
        "        input_text = reduce_masks(input, i, mask_str)\n",
        "\n",
        "        tokenized_input = tokenizer(input_text, return_tensors=\"tf\")\n",
        "\n",
        "        # checking if the model uses token_type_ids (not used in RoBERTa models)\n",
        "        use_token_type_ids = 'token_type_ids' in tokenized_input\n",
        "\n",
        "        input_ids = tokenized_input[\"input_ids\"]\n",
        "\n",
        "        # needed for confidence recomputation\n",
        "        initial_mask_token_indices = np.where(input_ids.numpy()[0] == tokenizer.mask_token_id)[0]\n",
        "\n",
        "        # not necessary to be computed\n",
        "        if verbose:\n",
        "          initial_confidence = 0\n",
        "\n",
        "        prediction_dict = {}\n",
        "        while True:\n",
        "\n",
        "          # finding all positions of the [MASK] tokens\n",
        "          mask_token_indices = np.where(input_ids.numpy()[0] == tokenizer.mask_token_id)[0]\n",
        "\n",
        "          # all tokens at mask positions are predicted\n",
        "          if len(mask_token_indices) == 0:\n",
        "            break\n",
        "\n",
        "          # getting token logits at mask_token_indices\n",
        "          token_logits = model(**tokenized_input).logits[0]\n",
        "          token_probs = tf.nn.softmax(token_logits, axis=-1)\n",
        "\n",
        "          mask_token_probs = tf.gather(token_probs, mask_token_indices)\n",
        "\n",
        "          mask_token_probs_candidates = tf.gather(mask_token_probs, candidate_set_tokens, axis=1)\n",
        "\n",
        "          # tf.matf.top_k returns k top values and indices from the input tensor along last dimension (by default)\n",
        "          top_values, top_indices = tf.math.top_k(mask_token_probs_candidates, k=1)\n",
        "\n",
        "          # finding original indices (token ids)\n",
        "          # converting candidate_set_tokens to a tf tensor\n",
        "          candidate_set_tokens_tensor = tf.constant(candidate_set_tokens, dtype=tf.int32)\n",
        "          # using tf.gather to transform the indices to corresponding values from candidate_set_tokens_tensor\n",
        "          top_indices_original = tf.gather(candidate_set_tokens_tensor, top_indices)\n",
        "\n",
        "          top_values = np.atleast_1d(tf.squeeze(top_values).numpy())\n",
        "          top_indices_original = np.atleast_1d(tf.squeeze(top_indices_original).numpy())\n",
        "\n",
        "          k = tf.argmax(top_values)\n",
        "          most_confident_mask_position, most_confident_token = mask_token_indices[k], top_indices_original[k]\n",
        "\n",
        "          if verbose:\n",
        "            initial_confidence += top_values[k]\n",
        "\n",
        "          if verbose:\n",
        "            print(f\"{most_confident_token}: {tokenizer.convert_ids_to_tokens([most_confident_token])} - index: {most_confident_mask_position}\")\n",
        "\n",
        "          prediction_dict[most_confident_mask_position] = most_confident_token\n",
        "\n",
        "          input_ids = tf.tensor_scatter_nd_update(input_ids, [[0, most_confident_mask_position]], [most_confident_token])\n",
        "\n",
        "          # making new tokenized_input tensor\n",
        "          if use_token_type_ids:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "              'token_type_ids': tokenized_input['token_type_ids']\n",
        "            }\n",
        "          else:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "            }\n",
        "\n",
        "        prediction = [value for key, value in sorted(prediction_dict.items())]\n",
        "        if verbose:\n",
        "          initial_confidence /= i\n",
        "          print(f'Prediction: {prediction} : {tokenizer.convert_ids_to_tokens(prediction)}')\n",
        "          print(f'Confidence before recomputing: {initial_confidence}')\n",
        "\n",
        "        # recompute confidence of every predicted token (this provides the probability of each token in the context of the entire sequence -  bidirectional conditional distributions)\n",
        "        confidence = 0\n",
        "        for mask_index in initial_mask_token_indices:\n",
        "          predicted_token = prediction_dict[mask_index]\n",
        "\n",
        "          # replacing predicted token with mask to remove bias\n",
        "          input_ids = tf.tensor_scatter_nd_update(input_ids, [[0, mask_index]], [tokenizer.mask_token_id])\n",
        "\n",
        "          if use_token_type_ids:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "              'token_type_ids': tokenized_input['token_type_ids']\n",
        "            }\n",
        "          else:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "            }\n",
        "\n",
        "          token_logits = model(**tokenized_input).logits[0]\n",
        "          token_probs = tf.nn.softmax(token_logits, axis=-1)\n",
        "          mask_token_probs = token_probs[mask_index, :]\n",
        "          # getting prob of predicted token in the context of the entire predicted sequence\n",
        "          confidence += mask_token_probs.numpy()[predicted_token]\n",
        "\n",
        "          # putting predicted token back to the context\n",
        "          input_ids = tf.tensor_scatter_nd_update(input_ids, [[0, mask_index]], [predicted_token])\n",
        "\n",
        "          if use_token_type_ids:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "              'token_type_ids': tokenized_input['token_type_ids']\n",
        "            }\n",
        "          else:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "            }\n",
        "\n",
        "        confidence /= i\n",
        "        if verbose:\n",
        "          print(f'Confidence after recomputing: {confidence}')\n",
        "\n",
        "        if confidence > max_confidence:\n",
        "          max_confidence = confidence\n",
        "          most_confident_prediction = prediction\n",
        "\n",
        "      outputs.append(most_confident_prediction)\n",
        "      prediction_decoded = tokenizer.decode(most_confident_prediction, skip_special_tokens=True)\n",
        "      outputs_decoded.append(prediction_decoded)\n",
        "      if verbose:\n",
        "        print('-----------------------------------------------------------------------------------')\n",
        "\n",
        "    return outputs, outputs_decoded"
      ],
      "metadata": {
        "id": "ns3RFXVJDIwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs, outputs_dec = fill_masks_by_confidence(bert_models['BERT_base'], test_inputs, verbose=1)\n",
        "\n",
        "test_tokenizer = AutoTokenizer.from_pretrained(bert_models['BERT_base'])\n",
        "\n",
        "i = 0\n",
        "for output, output_dec in zip(outputs, outputs_dec):\n",
        "  print(test_inputs[i])\n",
        "  print(f\"{output} : {output_dec} : {test_tokenizer.convert_ids_to_tokens(output)}\")\n",
        "  i += 1\n",
        "  print('-------------------------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxi1ztSL32jz",
        "outputId": "c1c4c07b-3a66-43ab-c98a-d33d62675d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen model: google-bert/bert-base-uncased\n",
            "Model: \"tf_bert_for_masked_lm_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  108891648 \n",
            "                                                                 \n",
            " mlm___cls (TFBertMLMHead)   multiple                  24459834  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109514298 (417.76 MB)\n",
            "Trainable params: 109514298 (417.76 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "2173: ['place'] - index: 4\n",
            "Prediction: [2173] : ['place']\n",
            "Confidence before recomputing: 0.7230950593948364\n",
            "Confidence after recomputing: 0.7230950593948364\n",
            "2173: ['place'] - index: 5\n",
            "2307: ['great'] - index: 4\n",
            "Prediction: [2307, 2173] : ['great', 'place']\n",
            "Confidence before recomputing: 0.5816580951213837\n",
            "Confidence after recomputing: 0.6126892864704132\n",
            "-----------------------------------------------------------------------------------\n",
            "3103: ['sun'] - index: 10\n",
            "Prediction: [3103] : ['sun']\n",
            "Confidence before recomputing: 0.20109564065933228\n",
            "Confidence after recomputing: 0.20109564065933228\n",
            "3103: ['sun'] - index: 10\n",
            "2291: ['system'] - index: 11\n",
            "Prediction: [3103, 2291] : ['sun', 'system']\n",
            "Confidence before recomputing: 0.3070455491542816\n",
            "Confidence after recomputing: 0.17841963648970705\n",
            "-----------------------------------------------------------------------------------\n",
            "4633: ['weather'] - index: 6\n",
            "Prediction: [4633] : ['weather']\n",
            "Confidence before recomputing: 0.3794039189815521\n",
            "Confidence after recomputing: 0.3794039189815521\n",
            "4633: ['weather'] - index: 7\n",
            "1996: ['the'] - index: 6\n",
            "Prediction: [1996, 4633] : ['the', 'weather']\n",
            "Confidence before recomputing: 0.7759885787963867\n",
            "Confidence after recomputing: 0.8356338739395142\n",
            "-----------------------------------------------------------------------------------\n",
            "4586: ['snow'] - index: 9\n",
            "Prediction: [4586] : ['snow']\n",
            "Confidence before recomputing: 0.483038067817688\n",
            "Confidence after recomputing: 0.483038067817688\n",
            "4586: ['snow'] - index: 9\n",
            "3785: ['conditions'] - index: 10\n",
            "Prediction: [4586, 3785] : ['snow', 'conditions']\n",
            "Confidence before recomputing: 0.18335624039173126\n",
            "Confidence after recomputing: 0.1136405635625124\n",
            "-----------------------------------------------------------------------------------\n",
            "2103: ['city'] - index: 10\n",
            "Prediction: [2103] : ['city']\n",
            "Confidence before recomputing: 0.13459141552448273\n",
            "Confidence after recomputing: 0.13459141552448273\n",
            "2088: ['world'] - index: 11\n",
            "3019: ['natural'] - index: 10\n",
            "Prediction: [3019, 2088] : ['natural', 'world']\n",
            "Confidence before recomputing: 0.26227474957704544\n",
            "Confidence after recomputing: 0.4765520244836807\n",
            "-----------------------------------------------------------------------------------\n",
            "4712: ['promotion'] - index: 8\n",
            "Prediction: [4712] : ['promotion']\n",
            "Confidence before recomputing: 0.11541903018951416\n",
            "Confidence after recomputing: 0.11541903018951416\n",
            "1996: ['the'] - index: 8\n",
            "3105: ['job'] - index: 9\n",
            "Prediction: [1996, 3105] : ['the', 'job']\n",
            "Confidence before recomputing: 0.18584313616156578\n",
            "Confidence after recomputing: 0.3171945624053478\n",
            "-----------------------------------------------------------------------------------\n",
            "12276: ['dedication'] - index: 8\n",
            "Prediction: [12276] : ['dedication']\n",
            "Confidence before recomputing: 0.18447323143482208\n",
            "Confidence after recomputing: 0.18447323143482208\n",
            "9128: ['determination'] - index: 9\n",
            "3167: ['personal'] - index: 8\n",
            "Prediction: [3167, 9128] : ['personal', 'determination']\n",
            "Confidence before recomputing: 0.10848244652152061\n",
            "Confidence after recomputing: 0.04609705810435116\n",
            "2010: ['his'] - index: 8\n",
            "5541: ['creative'] - index: 9\n",
            "2943: ['energy'] - index: 10\n",
            "Prediction: [2010, 5541, 2943] : ['his', 'creative', 'energy']\n",
            "Confidence before recomputing: 0.0721778894464175\n",
            "Confidence after recomputing: 0.2102151041229566\n",
            "-----------------------------------------------------------------------------------\n",
            "17363: ['scenery'] - index: 11\n",
            "Prediction: [17363] : ['scenery']\n",
            "Confidence before recomputing: 0.27261894941329956\n",
            "Confidence after recomputing: 0.27261894941329956\n",
            "10833: ['countryside'] - index: 12\n",
            "3059: ['italian'] - index: 11\n",
            "Prediction: [3059, 10833] : ['italian', 'countryside']\n",
            "Confidence before recomputing: 0.5083273202180862\n",
            "Confidence after recomputing: 0.6007926762104034\n",
            "3059: ['italian'] - index: 12\n",
            "10833: ['countryside'] - index: 13\n",
            "2670: ['southern'] - index: 11\n",
            "Prediction: [2670, 3059, 10833] : ['southern', 'italian', 'countryside']\n",
            "Confidence before recomputing: 0.30884600679079693\n",
            "Confidence after recomputing: 0.4431532919406891\n",
            "-----------------------------------------------------------------------------------\n",
            "4253: ['clothes'] - index: 12\n",
            "Prediction: [4253] : ['clothes']\n",
            "Confidence before recomputing: 0.20658248662948608\n",
            "Confidence after recomputing: 0.20658248662948608\n",
            "7852: ['bread'] - index: 13\n",
            "17776: ['baked'] - index: 12\n",
            "Prediction: [17776, 7852] : ['baked', 'bread']\n",
            "Confidence before recomputing: 0.15325529128313065\n",
            "Confidence after recomputing: 0.4735250771045685\n",
            "1010: [','] - index: 12\n",
            "4840: ['fresh'] - index: 13\n",
            "4253: ['clothes'] - index: 14\n",
            "Prediction: [1010, 4840, 4253] : [',', 'fresh', 'clothes']\n",
            "Confidence before recomputing: 0.321824053923289\n",
            "Confidence after recomputing: 0.49307260289788246\n",
            "1998: ['and'] - index: 13\n",
            "2070: ['some'] - index: 14\n",
            "4253: ['clothes'] - index: 12\n",
            "2833: ['food'] - index: 15\n",
            "Prediction: [4253, 1998, 2070, 2833] : ['clothes', 'and', 'some', 'food']\n",
            "Confidence before recomputing: 0.2503027841448784\n",
            "Confidence after recomputing: 0.6781444251537323\n",
            "-----------------------------------------------------------------------------------\n",
            "2168: ['same'] - index: 9\n",
            "Prediction: [2168] : ['same']\n",
            "Confidence before recomputing: 0.871084451675415\n",
            "Confidence after recomputing: 0.871084451675415\n",
            "2168: ['same'] - index: 9\n",
            "2168: ['same'] - index: 10\n",
            "Prediction: [2168, 2168] : ['same', 'same']\n",
            "Confidence before recomputing: 0.4657422564923763\n",
            "Confidence after recomputing: 0.10493944957852364\n",
            "4386: ['olympic'] - index: 10\n",
            "6042: ['qualifying'] - index: 11\n",
            "2355: ['2016'] - index: 9\n",
            "Prediction: [2355, 4386, 6042] : ['2016', 'olympic', 'qualifying']\n",
            "Confidence before recomputing: 0.15597146997849146\n",
            "Confidence after recomputing: 0.5228117058674494\n",
            "2399: ['games'] - index: 11\n",
            "5663: ['commonwealth'] - index: 10\n",
            "6482: ['athletics'] - index: 12\n",
            "2230: ['2010'] - index: 9\n",
            "Prediction: [2230, 5663, 2399, 6482] : ['2010', 'commonwealth', 'games', 'athletics']\n",
            "Confidence before recomputing: 0.23236512020230293\n",
            "Confidence after recomputing: 0.5744218975305557\n",
            "-----------------------------------------------------------------------------------\n",
            "Paris is a [MASK] [MASK] to visit.\n",
            "[2173] : place : ['place']\n",
            "-------------------------------------------------------------------------\n",
            "Jupyter is the largest planet of the [MASK] [MASK].\n",
            "[3103] : sun : ['sun']\n",
            "-------------------------------------------------------------------------\n",
            "The weather forecast predicts [MASK] [MASK] for tomorrow.\n",
            "[1996, 4633] : the weather : ['the', 'weather']\n",
            "-------------------------------------------------------------------------\n",
            "The weather forecast predicts heavy rain and [MASK] [MASK].\n",
            "[4586] : snow : ['snow']\n",
            "-------------------------------------------------------------------------\n",
            "He wanted to visit the museum and explore the [MASK] [MASK].\n",
            "[3019, 2088] : natural world : ['natural', 'world']\n",
            "-------------------------------------------------------------------------\n",
            "She was excited about the promotion and [MASK] [MASK].\n",
            "[1996, 3105] : the job : ['the', 'job']\n",
            "-------------------------------------------------------------------------\n",
            "He is known for his dedication and [MASK] [MASK] [MASK].\n",
            "[2010, 5541, 2943] : his creative energy : ['his', 'creative', 'energy']\n",
            "-------------------------------------------------------------------------\n",
            "They plan to travel to Italy and enjoy the beautiful [MASK] [MASK] [MASK].\n",
            "[3059, 10833] : italian countryside : ['italian', 'countryside']\n",
            "-------------------------------------------------------------------------\n",
            "She decided to go to the market and buy some fresh [MASK] [MASK] [MASK] [MASK].\n",
            "[4253, 1998, 2070, 2833] : clothes and some food : ['clothes', 'and', 'some', 'food']\n",
            "-------------------------------------------------------------------------\n",
            "He set a new world record at the [MASK] [MASK] [MASK] [MASK] event.\n",
            "[2168] : same : ['same']\n",
            "-------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conditional MLM\n",
        "# Initial predictions (Order) + Refinement (Order) until predictions converge or maximum number of iterations is reached\n",
        "# trying different mask token sequence lengths\n",
        "# ADD prediction length penalty (???)\n",
        "def fill_masks_autoregressively_with_refinement(model_checkpoint: str, inputs: list[str], candidate_set_tokens=None, max_iter=10, verbose=0):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "    model = TFAutoModelForMaskedLM.from_pretrained(model_checkpoint, from_pt=True)\n",
        "\n",
        "    mask_str = '[MASK]'\n",
        "    # Adjusting inputs for RoBERTa models\n",
        "    if 'roberta' in model_checkpoint:\n",
        "        mask_str = '<mask>'\n",
        "        inputs = [change_input_format(input) for input in inputs]\n",
        "\n",
        "    # model_max_length field not set by default for BioBERT and BioMedBERT models\n",
        "    if 'bio' in model_checkpoint.lower():\n",
        "        tokenizer.model_max_length = 512\n",
        "\n",
        "    if verbose:\n",
        "        print(f'Chosen model: {model_checkpoint}')\n",
        "        model.summary()\n",
        "\n",
        "    # if candidate_set_tokens is None, setting it to all tokens of the model\n",
        "    if candidate_set_tokens is None:\n",
        "      candidate_set_tokens = list(tokenizer.get_vocab().values()) # .keys() - decoded tokens (words/subwords)\n",
        "\n",
        "    outputs = []\n",
        "    outputs_decoded = []\n",
        "\n",
        "    for input in inputs:\n",
        "      # trying different mask token sequence lengths - from 1 to M (length of longest true answer)\n",
        "      M = input.count(mask_str)\n",
        "\n",
        "      max_confidence = 0\n",
        "      most_confident_prediction = None\n",
        "\n",
        "      for i in range(1, M+1):\n",
        "        input_text = reduce_masks(input, i, mask_str)\n",
        "\n",
        "        tokenized_input = tokenizer(input_text, return_tensors=\"tf\")\n",
        "\n",
        "        # checking if the model uses token_type_ids (not used in RoBERTa models)\n",
        "        use_token_type_ids = 'token_type_ids' in tokenized_input\n",
        "\n",
        "        input_ids = tokenized_input[\"input_ids\"]\n",
        "\n",
        "        # finding all positions of the [MASK] tokens\n",
        "        mask_token_indices = np.where(input_ids.numpy()[0] == tokenizer.mask_token_id)[0]\n",
        "\n",
        "        confidence = 0\n",
        "        prediction_dict = OrderedDict((mask_index, tokenizer.mask_token_id) for mask_index in mask_token_indices)\n",
        "\n",
        "        # making initial predictions\n",
        "        for mask_index in mask_token_indices:\n",
        "\n",
        "          token_logits = model(**tokenized_input).logits[0]\n",
        "          token_probs = tf.nn.softmax(token_logits, axis=-1)\n",
        "          mask_token_probs = token_probs[mask_index, :]\n",
        "\n",
        "          # getting the top predicted token from candidate set\n",
        "          top_token = candidate_set_tokens[np.argmax(mask_token_probs.numpy()[candidate_set_tokens])]\n",
        "          confidence += mask_token_probs.numpy()[top_token]\n",
        "\n",
        "          prediction_dict[mask_index] = top_token\n",
        "\n",
        "          input_ids = tf.tensor_scatter_nd_update(input_ids, [[0, mask_index]], [top_token])\n",
        "\n",
        "          # making new tokenized_input tensor\n",
        "          if use_token_type_ids:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "              'token_type_ids': tokenized_input['token_type_ids']\n",
        "            }\n",
        "          else:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "            }\n",
        "\n",
        "        confidence /= i\n",
        "\n",
        "        if verbose:\n",
        "          prediction_initial = [value for key, value in prediction_dict.items()]\n",
        "          prediction_initial_decoded = tokenizer.decode(prediction_initial, skip_special_tokens=True)\n",
        "          print(f'Initial prediction: {prediction_initial} : {tokenizer.convert_ids_to_tokens(prediction_initial)} : {prediction_initial_decoded}')\n",
        "          print(f'Initial confidence: {confidence}')\n",
        "\n",
        "        # refining predictions - UPDATE: replacing old predicted token with mask token before predicting to remove bias\n",
        "        for j in range(max_iter):\n",
        "\n",
        "          if verbose:\n",
        "            print(f\"Iteration: {j}\")\n",
        "\n",
        "          updated_tokens = 0\n",
        "          new_confidence = 0\n",
        "          for mask_index in mask_token_indices:\n",
        "            predicted_token = prediction_dict[mask_index]\n",
        "\n",
        "            # replacing predicted token with mask token to remove bias\n",
        "            input_ids = tf.tensor_scatter_nd_update(input_ids, [[0, mask_index]], [tokenizer.mask_token_id])\n",
        "\n",
        "            if use_token_type_ids:\n",
        "              tokenized_input = {\n",
        "                'input_ids': input_ids,\n",
        "                'attention_mask': tokenized_input['attention_mask'],\n",
        "                'token_type_ids': tokenized_input['token_type_ids']\n",
        "              }\n",
        "            else:\n",
        "              tokenized_input = {\n",
        "                'input_ids': input_ids,\n",
        "                'attention_mask': tokenized_input['attention_mask'],\n",
        "              }\n",
        "\n",
        "            token_logits = model(**tokenized_input).logits[0]\n",
        "            token_probs = tf.nn.softmax(token_logits, axis=-1)\n",
        "            mask_token_probs = token_probs[mask_index, :]\n",
        "\n",
        "            # getting the top predicted token from candidate set\n",
        "            top_token = candidate_set_tokens[np.argmax(mask_token_probs.numpy()[candidate_set_tokens])]\n",
        "            new_confidence += mask_token_probs.numpy()[top_token]\n",
        "\n",
        "            if prediction_dict[mask_index] != top_token:\n",
        "              prediction_dict[mask_index] = top_token\n",
        "              updated_tokens += 1\n",
        "\n",
        "            # putting predicted token to the context\n",
        "            input_ids = tf.tensor_scatter_nd_update(input_ids, [[0, mask_index]], [top_token])\n",
        "\n",
        "            # making new tokenized_input tensor\n",
        "            if use_token_type_ids:\n",
        "              tokenized_input = {\n",
        "                'input_ids': input_ids,\n",
        "                'attention_mask': tokenized_input['attention_mask'],\n",
        "                'token_type_ids': tokenized_input['token_type_ids']\n",
        "              }\n",
        "            else:\n",
        "              tokenized_input = {\n",
        "                'input_ids': input_ids,\n",
        "                'attention_mask': tokenized_input['attention_mask'],\n",
        "              }\n",
        "\n",
        "          # confidence can change even if no tokens are updated (we want the probability of each token recomputed in the context of the entire predicted sequence - bidirectional conditional distributions)\n",
        "          # SMALL ISSUE: if for max_iter iterations prediction changes (no convergence) final prediction confidence won't be recomputed - not happening in tested examples\n",
        "          confidence = new_confidence / i\n",
        "\n",
        "          if verbose:\n",
        "            prediction_j = [value for key, value in prediction_dict.items()]\n",
        "            prediction_j_decoded = tokenizer.decode(prediction_j, skip_special_tokens=True)\n",
        "            print(f'Prediction in iteration {j}: {prediction_j} : {tokenizer.convert_ids_to_tokens(prediction_j)} : {prediction_j_decoded}')\n",
        "            print(f'Confidence in iteration {j}: {confidence}')\n",
        "\n",
        "          # checking if convergence happened\n",
        "          if updated_tokens == 0:\n",
        "            if verbose:\n",
        "              print(f\"\\033[1mConvergence reached in iteration {j}!\\033[0m\")\n",
        "            break\n",
        "\n",
        "        if confidence > max_confidence:\n",
        "          max_confidence = confidence\n",
        "          most_confident_prediction = [value for key, value in prediction_dict.items()]\n",
        "\n",
        "        if verbose:\n",
        "          print('-------------------------------------------------------')\n",
        "\n",
        "      outputs.append(most_confident_prediction)\n",
        "      prediction_decoded = tokenizer.decode(most_confident_prediction, skip_special_tokens=True)\n",
        "      outputs_decoded.append(prediction_decoded)\n",
        "      if verbose:\n",
        "        print('------------------------------------------------------------------------------------------')\n",
        "\n",
        "    return outputs, outputs_decoded"
      ],
      "metadata": {
        "id": "S7_qcDbaDQ90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs, outputs_dec = fill_masks_autoregressively_with_refinement(bert_models['BERT_base'], test_inputs, verbose=1)\n",
        "\n",
        "test_tokenizer = AutoTokenizer.from_pretrained(bert_models['BERT_base'])\n",
        "i = 0\n",
        "for output, output_dec in zip(outputs, outputs_dec):\n",
        "  print(test_inputs[i])\n",
        "  print(f\"{output} : {output_dec} : {test_tokenizer.convert_ids_to_tokens(output)}\")\n",
        "  i += 1\n",
        "  print('-------------------------------------------------------------------------')"
      ],
      "metadata": {
        "id": "ZCgHlCth30CV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c37d4130-05a2-4c38-8df4-712f7e5581d0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen model: google-bert/bert-base-uncased\n",
            "Model: \"tf_bert_for_masked_lm_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  108891648 \n",
            "                                                                 \n",
            " mlm___cls (TFBertMLMHead)   multiple                  24459834  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109514298 (417.76 MB)\n",
            "Trainable params: 109514298 (417.76 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Initial prediction: [2173] : ['place'] : place\n",
            "Initial confidence: 0.7230950593948364\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [2173] : ['place'] : place\n",
            "Confidence in iteration 0: 0.7230950593948364\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [2307, 2173] : ['great', 'place'] : great place\n",
            "Initial confidence: 0.5600524544715881\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [2307, 2173] : ['great', 'place'] : great place\n",
            "Confidence in iteration 0: 0.6126892864704132\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Initial prediction: [3103] : ['sun'] : sun\n",
            "Initial confidence: 0.20109564065933228\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [3103] : ['sun'] : sun\n",
            "Confidence in iteration 0: 0.20109564065933228\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [3103, 2291] : ['sun', 'system'] : sun system\n",
            "Initial confidence: 0.3070455491542816\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [5943, 2291] : ['solar', 'system'] : solar system\n",
            "Confidence in iteration 0: 0.9963496923446655\n",
            "Iteration: 1\n",
            "Prediction in iteration 1: [5943, 2291] : ['solar', 'system'] : solar system\n",
            "Confidence in iteration 1: 0.9963496923446655\n",
            "\u001b[1mConvergence reached in iteration 1!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Initial prediction: [4633] : ['weather'] : weather\n",
            "Initial confidence: 0.3794039189815521\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [4633] : ['weather'] : weather\n",
            "Confidence in iteration 0: 0.3794039189815521\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [1996, 4633] : ['the', 'weather'] : the weather\n",
            "Initial confidence: 0.5253995656967163\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [1996, 4633] : ['the', 'weather'] : the weather\n",
            "Confidence in iteration 0: 0.8356338739395142\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Initial prediction: [4586] : ['snow'] : snow\n",
            "Initial confidence: 0.483038067817688\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [4586] : ['snow'] : snow\n",
            "Confidence in iteration 0: 0.483038067817688\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [4586, 3785] : ['snow', 'conditions'] : snow conditions\n",
            "Initial confidence: 0.18335624039173126\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [24706, 15717] : ['cloudy', 'skies'] : cloudy skies\n",
            "Confidence in iteration 0: 0.3366182744503021\n",
            "Iteration: 1\n",
            "Prediction in iteration 1: [24706, 15717] : ['cloudy', 'skies'] : cloudy skies\n",
            "Confidence in iteration 1: 0.47586682438850403\n",
            "\u001b[1mConvergence reached in iteration 1!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Initial prediction: [2103] : ['city'] : city\n",
            "Initial confidence: 0.13459141552448273\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [2103] : ['city'] : city\n",
            "Confidence in iteration 0: 0.13459141552448273\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [2334, 2381] : ['local', 'history'] : local history\n",
            "Initial confidence: 0.2138642519712448\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [2334, 2381] : ['local', 'history'] : local history\n",
            "Confidence in iteration 0: 0.567966639995575\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Initial prediction: [4712] : ['promotion'] : promotion\n",
            "Initial confidence: 0.11541903018951416\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [4712] : ['promotion'] : promotion\n",
            "Confidence in iteration 0: 0.11541903018951416\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [1996, 3105] : ['the', 'job'] : the job\n",
            "Initial confidence: 0.18584313616156578\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [1996, 3105] : ['the', 'job'] : the job\n",
            "Confidence in iteration 0: 0.3171945624053478\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Initial prediction: [12276] : ['dedication'] : dedication\n",
            "Initial confidence: 0.18447323143482208\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [12276] : ['dedication'] : dedication\n",
            "Confidence in iteration 0: 0.18447323143482208\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [3167, 12276] : ['personal', 'dedication'] : personal dedication\n",
            "Initial confidence: 0.0920996367931366\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [3167, 12276] : ['personal', 'dedication'] : personal dedication\n",
            "Confidence in iteration 0: 0.14569056034088135\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [2010, 5541, 2943] : ['his', 'creative', 'energy'] : his creative energy\n",
            "Initial confidence: 0.0721778894464175\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [2152, 1011, 2943] : ['high', '-', 'energy'] : high - energy\n",
            "Confidence in iteration 0: 0.20485581581791243\n",
            "Iteration: 1\n",
            "Prediction in iteration 1: [2152, 1011, 2943] : ['high', '-', 'energy'] : high - energy\n",
            "Confidence in iteration 1: 0.3604731820523739\n",
            "\u001b[1mConvergence reached in iteration 1!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Initial prediction: [17363] : ['scenery'] : scenery\n",
            "Initial confidence: 0.27261894941329956\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [17363] : ['scenery'] : scenery\n",
            "Confidence in iteration 0: 0.27261894941329956\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [3059, 10833] : ['italian', 'countryside'] : italian countryside\n",
            "Initial confidence: 0.40707463026046753\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [3059, 10833] : ['italian', 'countryside'] : italian countryside\n",
            "Confidence in iteration 0: 0.6007926762104034\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [3059, 2406, 17363] : ['italian', 'country', 'scenery'] : italian country scenery\n",
            "Initial confidence: 0.14479599396387735\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [3059, 2406, 17363] : ['italian', 'country', 'scenery'] : italian country scenery\n",
            "Confidence in iteration 0: 0.32345331211884815\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Initial prediction: [4253] : ['clothes'] : clothes\n",
            "Initial confidence: 0.20658248662948608\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [4253] : ['clothes'] : clothes\n",
            "Confidence in iteration 0: 0.20658248662948608\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [5909, 2612] : ['fruit', 'instead'] : fruit instead\n",
            "Initial confidence: 0.2653672359883785\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [11546, 2612] : ['vegetables', 'instead'] : vegetables instead\n",
            "Confidence in iteration 0: 0.3168068006634712\n",
            "Iteration: 1\n",
            "Prediction in iteration 1: [11546, 2612] : ['vegetables', 'instead'] : vegetables instead\n",
            "Confidence in iteration 1: 0.3168068006634712\n",
            "\u001b[1mConvergence reached in iteration 1!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [1010, 4840, 4253] : [',', 'fresh', 'clothes'] : , fresh clothes\n",
            "Initial confidence: 0.321824053923289\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [1010, 4550, 4253] : [',', 'clean', 'clothes'] : , clean clothes\n",
            "Confidence in iteration 0: 0.7304398914178213\n",
            "Iteration: 1\n",
            "Prediction in iteration 1: [1010, 4550, 4253] : [',', 'clean', 'clothes'] : , clean clothes\n",
            "Confidence in iteration 1: 0.6822245419025421\n",
            "\u001b[1mConvergence reached in iteration 1!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [11546, 2005, 1996, 2154] : ['vegetables', 'for', 'the', 'day'] : vegetables for the day\n",
            "Initial confidence: 0.38971314392983913\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [11546, 2005, 1996, 2154] : ['vegetables', 'for', 'the', 'day'] : vegetables for the day\n",
            "Confidence in iteration 0: 0.6266731545329094\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Initial prediction: [2168] : ['same'] : same\n",
            "Initial confidence: 0.871084451675415\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [2168] : ['same'] : same\n",
            "Confidence in iteration 0: 0.871084451675415\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [2168, 2168] : ['same', 'same'] : same same\n",
            "Initial confidence: 0.4657422564923763\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [2200, 2168] : ['very', 'same'] : very same\n",
            "Confidence in iteration 0: 0.78954216837883\n",
            "Iteration: 1\n",
            "Prediction in iteration 1: [2200, 2168] : ['very', 'same'] : very same\n",
            "Confidence in iteration 1: 0.78954216837883\n",
            "\u001b[1mConvergence reached in iteration 1!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [2230, 4386, 6042] : ['2010', 'olympic', 'qualifying'] : 2010 olympic qualifying\n",
            "Initial confidence: 0.15121306975682577\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [2355, 4386, 6042] : ['2016', 'olympic', 'qualifying'] : 2016 olympic qualifying\n",
            "Confidence in iteration 0: 0.5228117058674494\n",
            "Iteration: 1\n",
            "Prediction in iteration 1: [2355, 4386, 6042] : ['2016', 'olympic', 'qualifying'] : 2016 olympic qualifying\n",
            "Confidence in iteration 1: 0.5228117058674494\n",
            "\u001b[1mConvergence reached in iteration 1!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [2286, 2621, 3783, 6042] : ['2013', 'summer', 'olympics', 'qualifying'] : 2013 summer olympics qualifying\n",
            "Initial confidence: 0.35553621873259544\n",
            "Iteration: 0\n",
            "Prediction in iteration 0: [2262, 2621, 3783, 6042] : ['2012', 'summer', 'olympics', 'qualifying'] : 2012 summer olympics qualifying\n",
            "Confidence in iteration 0: 0.6170734390616417\n",
            "Iteration: 1\n",
            "Prediction in iteration 1: [2262, 2621, 3783, 6042] : ['2012', 'summer', 'olympics', 'qualifying'] : 2012 summer olympics qualifying\n",
            "Confidence in iteration 1: 0.6170734390616417\n",
            "\u001b[1mConvergence reached in iteration 1!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Paris is a [MASK] [MASK] to visit.\n",
            "[2173] : place : ['place']\n",
            "-------------------------------------------------------------------------\n",
            "Jupyter is the largest planet of the [MASK] [MASK].\n",
            "[5943, 2291] : solar system : ['solar', 'system']\n",
            "-------------------------------------------------------------------------\n",
            "The weather forecast predicts [MASK] [MASK] for tomorrow.\n",
            "[1996, 4633] : the weather : ['the', 'weather']\n",
            "-------------------------------------------------------------------------\n",
            "The weather forecast predicts heavy rain and [MASK] [MASK].\n",
            "[4586] : snow : ['snow']\n",
            "-------------------------------------------------------------------------\n",
            "He wanted to visit the museum and explore the [MASK] [MASK].\n",
            "[2334, 2381] : local history : ['local', 'history']\n",
            "-------------------------------------------------------------------------\n",
            "She was excited about the promotion and [MASK] [MASK].\n",
            "[1996, 3105] : the job : ['the', 'job']\n",
            "-------------------------------------------------------------------------\n",
            "He is known for his dedication and [MASK] [MASK] [MASK].\n",
            "[2152, 1011, 2943] : high - energy : ['high', '-', 'energy']\n",
            "-------------------------------------------------------------------------\n",
            "They plan to travel to Italy and enjoy the beautiful [MASK] [MASK] [MASK].\n",
            "[3059, 10833] : italian countryside : ['italian', 'countryside']\n",
            "-------------------------------------------------------------------------\n",
            "She decided to go to the market and buy some fresh [MASK] [MASK] [MASK] [MASK].\n",
            "[1010, 4550, 4253] : , clean clothes : [',', 'clean', 'clothes']\n",
            "-------------------------------------------------------------------------\n",
            "He set a new world record at the [MASK] [MASK] [MASK] [MASK] event.\n",
            "[2168] : same : ['same']\n",
            "-------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conditional MLM\n",
        "# Initial predictions (Greedy) + Refinement (Order) until predictions converge or maximum number of iterations is reached\n",
        "# trying different mask token sequence lengths\n",
        "# ADD prediction length penalty (???)\n",
        "def fill_masks_by_confidence_order_refinement(model_checkpoint: str, inputs: list[str], candidate_set_tokens=None, top_n=5, max_iter=10, verbose=0):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "    model = TFAutoModelForMaskedLM.from_pretrained(model_checkpoint, from_pt=True)\n",
        "\n",
        "    mask_str = '[MASK]'\n",
        "    # Adjusting inputs for RoBERTa models\n",
        "    if 'roberta' in model_checkpoint:\n",
        "        mask_str = '<mask>'\n",
        "        inputs = [change_input_format(input) for input in inputs]\n",
        "\n",
        "    # model_max_length field not set by default for BioBERT and BioMedBERT models\n",
        "    if 'bio' in model_checkpoint.lower():\n",
        "        tokenizer.model_max_length = 512\n",
        "\n",
        "    if verbose:\n",
        "        print(f'Chosen model: {model_checkpoint}')\n",
        "        model.summary()\n",
        "\n",
        "    # if candidate_set_tokens is None, setting it to all tokens of the model\n",
        "    if candidate_set_tokens is None:\n",
        "      candidate_set_tokens = list(tokenizer.get_vocab().values()) # .keys() - decoded tokens (words/subwords)\n",
        "\n",
        "    outputs = []\n",
        "    outputs_decoded = []\n",
        "\n",
        "    for input in inputs:\n",
        "      # trying different mask token sequence lengths - from 1 to M (length of longest true answer)\n",
        "      M = input.count(mask_str)\n",
        "\n",
        "      max_confidence = 0\n",
        "      most_confident_prediction = None\n",
        "\n",
        "      for i in range(1, M+1):\n",
        "        input_text = reduce_masks(input, i, mask_str)\n",
        "\n",
        "        tokenized_input = tokenizer(input_text, return_tensors=\"tf\")\n",
        "\n",
        "        # checking if the model uses token_type_ids (not used in RoBERTa models)\n",
        "        use_token_type_ids = 'token_type_ids' in tokenized_input\n",
        "\n",
        "        input_ids = tokenized_input[\"input_ids\"]\n",
        "\n",
        "        # needed for refinement phase\n",
        "        initial_mask_token_indices = np.where(input_ids.numpy()[0] == tokenizer.mask_token_id)[0]\n",
        "\n",
        "        confidence = 0\n",
        "        prediction_dict = {}\n",
        "\n",
        "        # Greedy initial\n",
        "        while True:\n",
        "\n",
        "          # finding all positions of the [MASK] tokens\n",
        "          mask_token_indices = np.where(input_ids.numpy()[0] == tokenizer.mask_token_id)[0]\n",
        "\n",
        "          # all tokens at mask positions are predicted\n",
        "          if len(mask_token_indices) == 0:\n",
        "            break\n",
        "\n",
        "          # getting token logits at mask_token_indices\n",
        "          token_logits = model(**tokenized_input).logits[0]\n",
        "          token_probs = tf.nn.softmax(token_logits, axis=-1)\n",
        "\n",
        "          mask_token_probs = tf.gather(token_probs, mask_token_indices)\n",
        "\n",
        "          mask_token_probs_candidates = tf.gather(mask_token_probs, candidate_set_tokens, axis=1)\n",
        "\n",
        "          # tf.matf.top_k returns k top values and indices from the input tensor along last dimension (by default)\n",
        "          top_values, top_indices = tf.math.top_k(mask_token_probs_candidates, k=1)\n",
        "\n",
        "          # finding original indices (token ids)\n",
        "          # converting candidate_set_tokens to a tf tensor\n",
        "          candidate_set_tokens_tensor = tf.constant(candidate_set_tokens, dtype=tf.int32)\n",
        "          # using tf.gather to transform the indices to corresponding values from candidate_set_tokens_tensor\n",
        "          top_indices_original = tf.gather(candidate_set_tokens_tensor, top_indices)\n",
        "\n",
        "          top_values = np.atleast_1d(tf.squeeze(top_values).numpy())\n",
        "          top_indices_original = np.atleast_1d(tf.squeeze(top_indices_original).numpy())\n",
        "\n",
        "          k = tf.argmax(top_values)\n",
        "          most_confident_mask_position, most_confident_token = mask_token_indices[k], top_indices_original[k]\n",
        "          confidence += top_values[k]\n",
        "\n",
        "          if verbose:\n",
        "            print(f\"{most_confident_token}: {tokenizer.convert_ids_to_tokens([most_confident_token])} - index: {most_confident_mask_position}\")\n",
        "\n",
        "          prediction_dict[most_confident_mask_position] = most_confident_token\n",
        "\n",
        "          input_ids = tf.tensor_scatter_nd_update(input_ids, [[0, most_confident_mask_position]], [most_confident_token])\n",
        "\n",
        "          # making new tokenized_input tensor\n",
        "          if use_token_type_ids:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "              'token_type_ids': tokenized_input['token_type_ids']\n",
        "            }\n",
        "          else:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "            }\n",
        "\n",
        "        confidence /= i\n",
        "        # sorting prediction_dict by mask positions\n",
        "        prediction_dict = OrderedDict({mask_position : prediction_dict[mask_position] for mask_position in sorted(prediction_dict)})\n",
        "\n",
        "        if verbose:\n",
        "          prediction_initial = [value for key, value in prediction_dict.items()]\n",
        "          prediction_initial_decoded = tokenizer.decode(prediction_initial, skip_special_tokens=True)\n",
        "          print(f'Initial greedy prediction: {prediction_initial} : {tokenizer.convert_ids_to_tokens(prediction_initial)} : {prediction_initial_decoded}')\n",
        "          print(f'Initial confidence: {confidence}')\n",
        "\n",
        "        # refining predictions - UPDATE: replacing old predicted token with mask token before predicting to remove bias\n",
        "        for j in range(max_iter):\n",
        "\n",
        "          if verbose:\n",
        "            print(f\"Iteration: {j}\")\n",
        "\n",
        "          updated_tokens = 0\n",
        "          new_confidence = 0\n",
        "          for mask_index in initial_mask_token_indices:\n",
        "            predicted_token = prediction_dict[mask_index]\n",
        "\n",
        "            # replacing predicted token with mask token to remove bias\n",
        "            input_ids = tf.tensor_scatter_nd_update(input_ids, [[0, mask_index]], [tokenizer.mask_token_id])\n",
        "\n",
        "            if use_token_type_ids:\n",
        "              tokenized_input = {\n",
        "                'input_ids': input_ids,\n",
        "                'attention_mask': tokenized_input['attention_mask'],\n",
        "                'token_type_ids': tokenized_input['token_type_ids']\n",
        "              }\n",
        "            else:\n",
        "              tokenized_input = {\n",
        "                'input_ids': input_ids,\n",
        "                'attention_mask': tokenized_input['attention_mask'],\n",
        "              }\n",
        "\n",
        "            token_logits = model(**tokenized_input).logits[0]\n",
        "            token_probs = tf.nn.softmax(token_logits, axis=-1)\n",
        "            mask_token_probs = token_probs[mask_index, :]\n",
        "\n",
        "            # getting the top predicted token from candidate set\n",
        "            top_token = candidate_set_tokens[np.argmax(mask_token_probs.numpy()[candidate_set_tokens])]\n",
        "            new_confidence += mask_token_probs.numpy()[top_token]\n",
        "\n",
        "            if prediction_dict[mask_index] != top_token:\n",
        "              prediction_dict[mask_index] = top_token\n",
        "              updated_tokens += 1\n",
        "\n",
        "            # putting predicted token to the context\n",
        "            input_ids = tf.tensor_scatter_nd_update(input_ids, [[0, mask_index]], [top_token])\n",
        "\n",
        "            # making new tokenized_input tensor\n",
        "            if use_token_type_ids:\n",
        "              tokenized_input = {\n",
        "                'input_ids': input_ids,\n",
        "                'attention_mask': tokenized_input['attention_mask'],\n",
        "                'token_type_ids': tokenized_input['token_type_ids']\n",
        "              }\n",
        "            else:\n",
        "              tokenized_input = {\n",
        "                'input_ids': input_ids,\n",
        "                'attention_mask': tokenized_input['attention_mask'],\n",
        "              }\n",
        "\n",
        "          # confidence can change even if no tokens are updated (we want the probability of each token recomputed in the context of the entire predicted sequence - bidirectional conditional distributions)\n",
        "          # SMALL ISSUE: if for max_iter iterations prediction changes (no convergence) final prediction confidence won't be recomputed - not happening in tested examples\n",
        "          confidence = new_confidence / i\n",
        "\n",
        "          if verbose:\n",
        "            prediction_j = [value for key, value in prediction_dict.items()]\n",
        "            prediction_j_decoded = tokenizer.decode(prediction_j, skip_special_tokens=True)\n",
        "            print(f'Prediction in iteration {j} : {prediction_j} : {tokenizer.convert_ids_to_tokens(prediction_j)} : {prediction_j_decoded}')\n",
        "            print(f'Confidence in iteration {j}: {confidence}')\n",
        "\n",
        "          # checking if convergence happened\n",
        "          if updated_tokens == 0:\n",
        "            if verbose:\n",
        "              print(f\"\\033[1mConvergence reached in iteration {j}!\\033[0m\")\n",
        "            break\n",
        "\n",
        "        if confidence > max_confidence:\n",
        "          max_confidence = confidence\n",
        "          most_confident_prediction = [value for key, value in prediction_dict.items()]\n",
        "\n",
        "        if verbose:\n",
        "          print('-------------------------------------------------------')\n",
        "\n",
        "      outputs.append(most_confident_prediction)\n",
        "      prediction_decoded = tokenizer.decode(most_confident_prediction, skip_special_tokens=True)\n",
        "      outputs_decoded.append(prediction_decoded)\n",
        "      if verbose:\n",
        "        print('------------------------------------------------------------------------------------------')\n",
        "\n",
        "    return outputs, outputs_decoded"
      ],
      "metadata": {
        "id": "V3dKOubYDYnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs, outputs_dec = fill_masks_by_confidence_order_refinement(bert_models['BERT_base'], test_inputs, verbose=1)\n",
        "\n",
        "test_tokenizer = AutoTokenizer.from_pretrained(bert_models['BERT_base'])\n",
        "i = 0\n",
        "for output, output_dec in zip(outputs, outputs_dec):\n",
        "  print(test_inputs[i])\n",
        "  print(f\"{output} : {output_dec} : {test_tokenizer.convert_ids_to_tokens(output)}\")\n",
        "  i += 1\n",
        "  print('-------------------------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H1HUqUg6g-K",
        "outputId": "94b0bf85-38d7-4df0-d31e-a8cea5007dbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen model: google-bert/bert-base-uncased\n",
            "Model: \"tf_bert_for_masked_lm_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  108891648 \n",
            "                                                                 \n",
            " mlm___cls (TFBertMLMHead)   multiple                  24459834  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109514298 (417.76 MB)\n",
            "Trainable params: 109514298 (417.76 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "2173: ['place'] - index: 4\n",
            "Initial greedy prediction: [2173] : ['place'] : place\n",
            "Initial confidence: 0.7230950593948364\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [2173] : ['place'] : place\n",
            "Confidence in iteration 0: 0.7230950593948364\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "2173: ['place'] - index: 5\n",
            "2307: ['great'] - index: 4\n",
            "Initial greedy prediction: [2307, 2173] : ['great', 'place'] : great place\n",
            "Initial confidence: 0.5816580951213837\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [2307, 2173] : ['great', 'place'] : great place\n",
            "Confidence in iteration 0: 0.6126892864704132\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "3103: ['sun'] - index: 10\n",
            "Initial greedy prediction: [3103] : ['sun'] : sun\n",
            "Initial confidence: 0.20109564065933228\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [3103] : ['sun'] : sun\n",
            "Confidence in iteration 0: 0.20109564065933228\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "3103: ['sun'] - index: 10\n",
            "2291: ['system'] - index: 11\n",
            "Initial greedy prediction: [3103, 2291] : ['sun', 'system'] : sun system\n",
            "Initial confidence: 0.3070455491542816\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [5943, 2291] : ['solar', 'system'] : solar system\n",
            "Confidence in iteration 0: 0.9963496923446655\n",
            "Iteration: 1\n",
            "Prediction in iteration 1 : [5943, 2291] : ['solar', 'system'] : solar system\n",
            "Confidence in iteration 1: 0.9963496923446655\n",
            "\u001b[1mConvergence reached in iteration 1!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "4633: ['weather'] - index: 6\n",
            "Initial greedy prediction: [4633] : ['weather'] : weather\n",
            "Initial confidence: 0.3794039189815521\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [4633] : ['weather'] : weather\n",
            "Confidence in iteration 0: 0.3794039189815521\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "4633: ['weather'] - index: 7\n",
            "1996: ['the'] - index: 6\n",
            "Initial greedy prediction: [1996, 4633] : ['the', 'weather'] : the weather\n",
            "Initial confidence: 0.7759885787963867\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [1996, 4633] : ['the', 'weather'] : the weather\n",
            "Confidence in iteration 0: 0.8356338739395142\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "4586: ['snow'] - index: 9\n",
            "Initial greedy prediction: [4586] : ['snow'] : snow\n",
            "Initial confidence: 0.483038067817688\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [4586] : ['snow'] : snow\n",
            "Confidence in iteration 0: 0.483038067817688\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "4586: ['snow'] - index: 9\n",
            "3785: ['conditions'] - index: 10\n",
            "Initial greedy prediction: [4586, 3785] : ['snow', 'conditions'] : snow conditions\n",
            "Initial confidence: 0.18335624039173126\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [24706, 15717] : ['cloudy', 'skies'] : cloudy skies\n",
            "Confidence in iteration 0: 0.3366182744503021\n",
            "Iteration: 1\n",
            "Prediction in iteration 1 : [24706, 15717] : ['cloudy', 'skies'] : cloudy skies\n",
            "Confidence in iteration 1: 0.47586682438850403\n",
            "\u001b[1mConvergence reached in iteration 1!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "2103: ['city'] - index: 10\n",
            "Initial greedy prediction: [2103] : ['city'] : city\n",
            "Initial confidence: 0.13459141552448273\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [2103] : ['city'] : city\n",
            "Confidence in iteration 0: 0.13459141552448273\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "2088: ['world'] - index: 11\n",
            "3019: ['natural'] - index: 10\n",
            "Initial greedy prediction: [3019, 2088] : ['natural', 'world'] : natural world\n",
            "Initial confidence: 0.26227474957704544\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [3019, 2088] : ['natural', 'world'] : natural world\n",
            "Confidence in iteration 0: 0.4765520244836807\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "4712: ['promotion'] - index: 8\n",
            "Initial greedy prediction: [4712] : ['promotion'] : promotion\n",
            "Initial confidence: 0.11541903018951416\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [4712] : ['promotion'] : promotion\n",
            "Confidence in iteration 0: 0.11541903018951416\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "1996: ['the'] - index: 8\n",
            "3105: ['job'] - index: 9\n",
            "Initial greedy prediction: [1996, 3105] : ['the', 'job'] : the job\n",
            "Initial confidence: 0.18584313616156578\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [1996, 3105] : ['the', 'job'] : the job\n",
            "Confidence in iteration 0: 0.3171945624053478\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "12276: ['dedication'] - index: 8\n",
            "Initial greedy prediction: [12276] : ['dedication'] : dedication\n",
            "Initial confidence: 0.18447323143482208\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [12276] : ['dedication'] : dedication\n",
            "Confidence in iteration 0: 0.18447323143482208\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "9128: ['determination'] - index: 9\n",
            "3167: ['personal'] - index: 8\n",
            "Initial greedy prediction: [3167, 9128] : ['personal', 'determination'] : personal determination\n",
            "Initial confidence: 0.10848244652152061\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [3167, 12276] : ['personal', 'dedication'] : personal dedication\n",
            "Confidence in iteration 0: 0.11384474113583565\n",
            "Iteration: 1\n",
            "Prediction in iteration 1 : [3167, 12276] : ['personal', 'dedication'] : personal dedication\n",
            "Confidence in iteration 1: 0.14569056034088135\n",
            "\u001b[1mConvergence reached in iteration 1!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "2010: ['his'] - index: 8\n",
            "5541: ['creative'] - index: 9\n",
            "2943: ['energy'] - index: 10\n",
            "Initial greedy prediction: [2010, 5541, 2943] : ['his', 'creative', 'energy'] : his creative energy\n",
            "Initial confidence: 0.0721778894464175\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [2152, 1011, 2943] : ['high', '-', 'energy'] : high - energy\n",
            "Confidence in iteration 0: 0.20485581581791243\n",
            "Iteration: 1\n",
            "Prediction in iteration 1 : [2152, 1011, 2943] : ['high', '-', 'energy'] : high - energy\n",
            "Confidence in iteration 1: 0.3604731820523739\n",
            "\u001b[1mConvergence reached in iteration 1!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "17363: ['scenery'] - index: 11\n",
            "Initial greedy prediction: [17363] : ['scenery'] : scenery\n",
            "Initial confidence: 0.27261894941329956\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [17363] : ['scenery'] : scenery\n",
            "Confidence in iteration 0: 0.27261894941329956\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "10833: ['countryside'] - index: 12\n",
            "3059: ['italian'] - index: 11\n",
            "Initial greedy prediction: [3059, 10833] : ['italian', 'countryside'] : italian countryside\n",
            "Initial confidence: 0.5083273202180862\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [3059, 10833] : ['italian', 'countryside'] : italian countryside\n",
            "Confidence in iteration 0: 0.6007926762104034\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "3059: ['italian'] - index: 12\n",
            "10833: ['countryside'] - index: 13\n",
            "2670: ['southern'] - index: 11\n",
            "Initial greedy prediction: [2670, 3059, 10833] : ['southern', 'italian', 'countryside'] : southern italian countryside\n",
            "Initial confidence: 0.30884600679079693\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [2670, 3059, 10833] : ['southern', 'italian', 'countryside'] : southern italian countryside\n",
            "Confidence in iteration 0: 0.4431532919406891\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "4253: ['clothes'] - index: 12\n",
            "Initial greedy prediction: [4253] : ['clothes'] : clothes\n",
            "Initial confidence: 0.20658248662948608\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [4253] : ['clothes'] : clothes\n",
            "Confidence in iteration 0: 0.20658248662948608\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "7852: ['bread'] - index: 13\n",
            "17776: ['baked'] - index: 12\n",
            "Initial greedy prediction: [17776, 7852] : ['baked', 'bread'] : baked bread\n",
            "Initial confidence: 0.15325529128313065\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [17776, 7852] : ['baked', 'bread'] : baked bread\n",
            "Confidence in iteration 0: 0.4735250771045685\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "1010: [','] - index: 12\n",
            "4840: ['fresh'] - index: 13\n",
            "4253: ['clothes'] - index: 14\n",
            "Initial greedy prediction: [1010, 4840, 4253] : [',', 'fresh', 'clothes'] : , fresh clothes\n",
            "Initial confidence: 0.321824053923289\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [1010, 4550, 4253] : [',', 'clean', 'clothes'] : , clean clothes\n",
            "Confidence in iteration 0: 0.7304398914178213\n",
            "Iteration: 1\n",
            "Prediction in iteration 1 : [1010, 4550, 4253] : [',', 'clean', 'clothes'] : , clean clothes\n",
            "Confidence in iteration 1: 0.6822245419025421\n",
            "\u001b[1mConvergence reached in iteration 1!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "1998: ['and'] - index: 13\n",
            "2070: ['some'] - index: 14\n",
            "4253: ['clothes'] - index: 12\n",
            "2833: ['food'] - index: 15\n",
            "Initial greedy prediction: [4253, 1998, 2070, 2833] : ['clothes', 'and', 'some', 'food'] : clothes and some food\n",
            "Initial confidence: 0.2503027841448784\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [4253, 1998, 2070, 2833] : ['clothes', 'and', 'some', 'food'] : clothes and some food\n",
            "Confidence in iteration 0: 0.6781444251537323\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "2168: ['same'] - index: 9\n",
            "Initial greedy prediction: [2168] : ['same'] : same\n",
            "Initial confidence: 0.871084451675415\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [2168] : ['same'] : same\n",
            "Confidence in iteration 0: 0.871084451675415\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "2168: ['same'] - index: 9\n",
            "2168: ['same'] - index: 10\n",
            "Initial greedy prediction: [2168, 2168] : ['same', 'same'] : same same\n",
            "Initial confidence: 0.4657422564923763\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [2200, 2168] : ['very', 'same'] : very same\n",
            "Confidence in iteration 0: 0.78954216837883\n",
            "Iteration: 1\n",
            "Prediction in iteration 1 : [2200, 2168] : ['very', 'same'] : very same\n",
            "Confidence in iteration 1: 0.78954216837883\n",
            "\u001b[1mConvergence reached in iteration 1!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "4386: ['olympic'] - index: 10\n",
            "6042: ['qualifying'] - index: 11\n",
            "2355: ['2016'] - index: 9\n",
            "Initial greedy prediction: [2355, 4386, 6042] : ['2016', 'olympic', 'qualifying'] : 2016 olympic qualifying\n",
            "Initial confidence: 0.15597146997849146\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [2355, 4386, 6042] : ['2016', 'olympic', 'qualifying'] : 2016 olympic qualifying\n",
            "Confidence in iteration 0: 0.5228117058674494\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "2399: ['games'] - index: 11\n",
            "5663: ['commonwealth'] - index: 10\n",
            "6482: ['athletics'] - index: 12\n",
            "2230: ['2010'] - index: 9\n",
            "Initial greedy prediction: [2230, 5663, 2399, 6482] : ['2010', 'commonwealth', 'games', 'athletics'] : 2010 commonwealth games athletics\n",
            "Initial confidence: 0.23236512020230293\n",
            "Iteration: 0\n",
            "Prediction in iteration 0 : [2230, 5663, 2399, 6482] : ['2010', 'commonwealth', 'games', 'athletics'] : 2010 commonwealth games athletics\n",
            "Confidence in iteration 0: 0.5744218975305557\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Paris is a [MASK] [MASK] to visit.\n",
            "[2173] : place : ['place']\n",
            "-------------------------------------------------------------------------\n",
            "Jupyter is the largest planet of the [MASK] [MASK].\n",
            "[5943, 2291] : solar system : ['solar', 'system']\n",
            "-------------------------------------------------------------------------\n",
            "The weather forecast predicts [MASK] [MASK] for tomorrow.\n",
            "[1996, 4633] : the weather : ['the', 'weather']\n",
            "-------------------------------------------------------------------------\n",
            "The weather forecast predicts heavy rain and [MASK] [MASK].\n",
            "[4586] : snow : ['snow']\n",
            "-------------------------------------------------------------------------\n",
            "He wanted to visit the museum and explore the [MASK] [MASK].\n",
            "[3019, 2088] : natural world : ['natural', 'world']\n",
            "-------------------------------------------------------------------------\n",
            "She was excited about the promotion and [MASK] [MASK].\n",
            "[1996, 3105] : the job : ['the', 'job']\n",
            "-------------------------------------------------------------------------\n",
            "He is known for his dedication and [MASK] [MASK] [MASK].\n",
            "[2152, 1011, 2943] : high - energy : ['high', '-', 'energy']\n",
            "-------------------------------------------------------------------------\n",
            "They plan to travel to Italy and enjoy the beautiful [MASK] [MASK] [MASK].\n",
            "[3059, 10833] : italian countryside : ['italian', 'countryside']\n",
            "-------------------------------------------------------------------------\n",
            "She decided to go to the market and buy some fresh [MASK] [MASK] [MASK] [MASK].\n",
            "[1010, 4550, 4253] : , clean clothes : [',', 'clean', 'clothes']\n",
            "-------------------------------------------------------------------------\n",
            "He set a new world record at the [MASK] [MASK] [MASK] [MASK] event.\n",
            "[2168] : same : ['same']\n",
            "-------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conditional MLM\n",
        "# Initial predictions (Order) + Refinement (Greedy) until predictions converge or maximum number of iterations is reached\n",
        "# trying different mask token sequence lengths\n",
        "# ADD prediction length penalty (???)\n",
        "def fill_masks_autoregressively_greedy_refinement(model_checkpoint: str, inputs: list[str], candidate_set_tokens=None, max_iter=10, verbose=0):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "    model = TFAutoModelForMaskedLM.from_pretrained(model_checkpoint, from_pt=True)\n",
        "\n",
        "    mask_str = '[MASK]'\n",
        "    # Adjusting inputs for RoBERTa models\n",
        "    if 'roberta' in model_checkpoint:\n",
        "        mask_str = '<mask>'\n",
        "        inputs = [change_input_format(input) for input in inputs]\n",
        "\n",
        "    # model_max_length field not set by default for BioBERT and BioMedBERT models\n",
        "    if 'bio' in model_checkpoint.lower():\n",
        "        tokenizer.model_max_length = 512\n",
        "\n",
        "    if verbose:\n",
        "        print(f'Chosen model: {model_checkpoint}')\n",
        "        model.summary()\n",
        "\n",
        "    # if candidate_set_tokens is None, setting it to all tokens of the model\n",
        "    if candidate_set_tokens is None:\n",
        "      candidate_set_tokens = list(tokenizer.get_vocab().values()) # .keys() - decoded tokens (words/subwords)\n",
        "\n",
        "    outputs = []\n",
        "    outputs_decoded = []\n",
        "\n",
        "    for input in inputs:\n",
        "      # trying different mask token sequence lengths - from 1 to M (length of longest true answer)\n",
        "      M = input.count(mask_str)\n",
        "\n",
        "      max_confidence = 0\n",
        "      most_confident_prediction = None\n",
        "\n",
        "      for i in range(1, M+1):\n",
        "        input_text = reduce_masks(input, i, mask_str)\n",
        "\n",
        "        tokenized_input = tokenizer(input_text, return_tensors=\"tf\")\n",
        "\n",
        "        # checking if the model uses token_type_ids (not used in RoBERTa models)\n",
        "        use_token_type_ids = 'token_type_ids' in tokenized_input\n",
        "\n",
        "        input_ids = tokenized_input[\"input_ids\"]\n",
        "\n",
        "        # finding all positions of the [MASK] tokens\n",
        "        mask_token_indices = np.where(input_ids.numpy()[0] == tokenizer.mask_token_id)[0]\n",
        "\n",
        "        prediction_dict = OrderedDict((mask_index, tokenizer.mask_token_id) for mask_index in mask_token_indices)\n",
        "\n",
        "        # not necessary to be computed\n",
        "        if verbose:\n",
        "          initial_probs_dict = OrderedDict((mask_index, -1) for mask_index in mask_token_indices)\n",
        "\n",
        "        # making initial predictions\n",
        "        for mask_index in mask_token_indices:\n",
        "\n",
        "          token_logits = model(**tokenized_input).logits[0]\n",
        "          token_probs = tf.nn.softmax(token_logits, axis=-1)\n",
        "          mask_token_probs = token_probs[mask_index, :]\n",
        "\n",
        "          # getting the top predicted token from candidate set\n",
        "          top_token = candidate_set_tokens[np.argmax(mask_token_probs.numpy()[candidate_set_tokens])]\n",
        "          prediction_dict[mask_index] = top_token\n",
        "\n",
        "          if verbose:\n",
        "            token_prob = mask_token_probs.numpy()[top_token]\n",
        "            initial_probs_dict[mask_index] = token_prob\n",
        "\n",
        "          input_ids = tf.tensor_scatter_nd_update(input_ids, [[0, mask_index]], [top_token])\n",
        "\n",
        "          # making new tokenized_input tensor\n",
        "          if use_token_type_ids:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "              'token_type_ids': tokenized_input['token_type_ids']\n",
        "            }\n",
        "          else:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "            }\n",
        "\n",
        "        if verbose:\n",
        "          prediction_initial = [value for key, value in prediction_dict.items()]\n",
        "          initial_probs = [value for key, value in initial_probs_dict.items()]\n",
        "          prediction_initial_decoded = tokenizer.decode(prediction_initial, skip_special_tokens=True)\n",
        "          print(f'Initial prediction: {prediction_initial} : {tokenizer.convert_ids_to_tokens(prediction_initial)} : {prediction_initial_decoded}')\n",
        "          print(f'Initial probs: {initial_probs}')\n",
        "\n",
        "        # refining predictions\n",
        "        for j in range(max_iter):\n",
        "\n",
        "          if verbose:\n",
        "            print(f\"Iteration: {j}\")\n",
        "\n",
        "          # recomputing prob of every token in the context of the entire predicted sequence - bidirectional conditional distributions\n",
        "          probs_dict = OrderedDict((mask_index, -1) for mask_index in mask_token_indices)\n",
        "          for mask_index in mask_token_indices:\n",
        "            predicted_token = prediction_dict[mask_index]\n",
        "\n",
        "            # replacing predicted token with mask to remove bias\n",
        "            input_ids = tf.tensor_scatter_nd_update(input_ids, [[0, mask_index]], [tokenizer.mask_token_id])\n",
        "\n",
        "            if use_token_type_ids:\n",
        "              tokenized_input = {\n",
        "                'input_ids': input_ids,\n",
        "                'attention_mask': tokenized_input['attention_mask'],\n",
        "                'token_type_ids': tokenized_input['token_type_ids']\n",
        "              }\n",
        "            else:\n",
        "              tokenized_input = {\n",
        "                'input_ids': input_ids,\n",
        "                'attention_mask': tokenized_input['attention_mask'],\n",
        "              }\n",
        "\n",
        "            token_logits = model(**tokenized_input).logits[0]\n",
        "            token_probs = tf.nn.softmax(token_logits, axis=-1)\n",
        "            mask_token_probs = token_probs[mask_index, :]\n",
        "            # getting prob of predicted token in the context of the entire predicted sequence\n",
        "\n",
        "            token_prob = mask_token_probs.numpy()[predicted_token]\n",
        "            probs_dict[mask_index] = token_prob\n",
        "\n",
        "            # putting predicted token back to the context\n",
        "            input_ids = tf.tensor_scatter_nd_update(input_ids, [[0, mask_index]], [predicted_token])\n",
        "\n",
        "            if use_token_type_ids:\n",
        "              tokenized_input = {\n",
        "                'input_ids': input_ids,\n",
        "                'attention_mask': tokenized_input['attention_mask'],\n",
        "                'token_type_ids': tokenized_input['token_type_ids']\n",
        "              }\n",
        "            else:\n",
        "              tokenized_input = {\n",
        "                'input_ids': input_ids,\n",
        "                'attention_mask': tokenized_input['attention_mask'],\n",
        "              }\n",
        "\n",
        "          if verbose:\n",
        "            probs = [value for key, value in probs_dict.items()]\n",
        "            print(f'Recomputed probs {j}: {probs}')\n",
        "\n",
        "          # finding token with the lowest prob\n",
        "          min_mask_index = min(probs_dict, key=lambda mask_index: probs_dict[mask_index])\n",
        "          min_token = prediction_dict[min_mask_index]\n",
        "\n",
        "          if verbose:\n",
        "            print(f'Token with lowest confidence: {tokenizer.convert_ids_to_tokens(min_token)}')\n",
        "\n",
        "          # repredicting token with lowest confidence\n",
        "          input_ids = tf.tensor_scatter_nd_update(input_ids, [[0, min_mask_index]], [tokenizer.mask_token_id])\n",
        "\n",
        "          if use_token_type_ids:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "              'token_type_ids': tokenized_input['token_type_ids']\n",
        "            }\n",
        "          else:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "            }\n",
        "\n",
        "          token_logits = model(**tokenized_input).logits[0]\n",
        "          token_probs = tf.nn.softmax(token_logits, axis=-1)\n",
        "          min_mask_index_probs = token_probs[min_mask_index, :]\n",
        "\n",
        "          new_predicted_token = candidate_set_tokens[np.argmax(min_mask_index_probs.numpy()[candidate_set_tokens])]\n",
        "\n",
        "          prediction_dict[min_mask_index] = new_predicted_token\n",
        "          probs_dict[min_mask_index] = min_mask_index_probs.numpy()[new_predicted_token]\n",
        "\n",
        "          input_ids = tf.tensor_scatter_nd_update(input_ids, [[0, min_mask_index]], [new_predicted_token])\n",
        "\n",
        "          if use_token_type_ids:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "              'token_type_ids': tokenized_input['token_type_ids']\n",
        "            }\n",
        "          else:\n",
        "            tokenized_input = {\n",
        "              'input_ids': input_ids,\n",
        "              'attention_mask': tokenized_input['attention_mask'],\n",
        "            }\n",
        "\n",
        "          if verbose:\n",
        "            prediction_j = [value for key, value in prediction_dict.items()]\n",
        "            prediction_j_decoded = tokenizer.decode(prediction_j, skip_special_tokens=True)\n",
        "            probs_j = [value for key, value in probs_dict.items()]\n",
        "            print(f'Prediction after iteration {j} : {prediction_j} : {tokenizer.convert_ids_to_tokens(prediction_j)} : {prediction_j_decoded}')\n",
        "            print(f'Probs after iteration {j}: {probs_j}')\n",
        "\n",
        "          # checking if convergence happened\n",
        "          if new_predicted_token == min_token:\n",
        "            if verbose:\n",
        "              print(f\"\\033[1mConvergence reached in iteration {j}!\\033[0m\")\n",
        "            break\n",
        "\n",
        "        confidence = sum([value for key, value in probs_dict.items()]) / i\n",
        "        if confidence > max_confidence:\n",
        "          max_confidence = confidence\n",
        "          most_confident_prediction = [value for key, value in prediction_dict.items()]\n",
        "\n",
        "        if verbose:\n",
        "          print('-------------------------------------------------------')\n",
        "\n",
        "      outputs.append(most_confident_prediction)\n",
        "      prediction_decoded = tokenizer.decode(most_confident_prediction, skip_special_tokens=True)\n",
        "      outputs_decoded.append(prediction_decoded)\n",
        "      if verbose:\n",
        "        print('------------------------------------------------------------------------------------------')\n",
        "\n",
        "    return outputs, outputs_decoded"
      ],
      "metadata": {
        "id": "NFX05dpII3qK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs, outputs_dec = fill_masks_autoregressively_greedy_refinement(bert_models['BERT_base'], test_inputs, verbose=1)\n",
        "\n",
        "test_tokenizer = AutoTokenizer.from_pretrained(bert_models['BERT_base'])\n",
        "i = 0\n",
        "for output, output_dec in zip(outputs, outputs_dec):\n",
        "  print(test_inputs[i])\n",
        "  print(f\"{output} : {output_dec} : {test_tokenizer.convert_ids_to_tokens(output)}\")\n",
        "  i += 1\n",
        "  print('-------------------------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86AJ0XOYaM_W",
        "outputId": "57fea1d1-c30a-49c8-c265-26b05a9fd816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen model: google-bert/bert-base-uncased\n",
            "Model: \"tf_bert_for_masked_lm_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  108891648 \n",
            "                                                                 \n",
            " mlm___cls (TFBertMLMHead)   multiple                  24459834  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109514298 (417.76 MB)\n",
            "Trainable params: 109514298 (417.76 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Initial prediction: [2173] : ['place'] : place\n",
            "Initial probs: [0.72309506]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.72309506]\n",
            "Token with lowest confidence: place\n",
            "Prediction after iteration 0 : [2173] : ['place'] : place\n",
            "Probs after iteration 0: [0.72309506]\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [2307, 2173] : ['great', 'place'] : great place\n",
            "Initial probs: [0.24371475, 0.87639016]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.3489884, 0.87639016]\n",
            "Token with lowest confidence: great\n",
            "Prediction after iteration 0 : [2307, 2173] : ['great', 'place'] : great place\n",
            "Probs after iteration 0: [0.3489884, 0.87639016]\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Initial prediction: [3103] : ['sun'] : sun\n",
            "Initial probs: [0.20109564]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.20109564]\n",
            "Token with lowest confidence: sun\n",
            "Prediction after iteration 0 : [3103] : ['sun'] : sun\n",
            "Probs after iteration 0: [0.20109564]\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [3103, 2291] : ['sun', 'system'] : sun system\n",
            "Initial probs: [0.25741994, 0.35667115]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.00016811848, 0.35667115]\n",
            "Token with lowest confidence: sun\n",
            "Prediction after iteration 0 : [5943, 2291] : ['solar', 'system'] : solar system\n",
            "Probs after iteration 0: [0.99426407, 0.35667115]\n",
            "Iteration: 1\n",
            "Recomputed probs 1: [0.99426407, 0.9984353]\n",
            "Token with lowest confidence: solar\n",
            "Prediction after iteration 1 : [5943, 2291] : ['solar', 'system'] : solar system\n",
            "Probs after iteration 1: [0.99426407, 0.9984353]\n",
            "\u001b[1mConvergence reached in iteration 1!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Initial prediction: [4633] : ['weather'] : weather\n",
            "Initial probs: [0.37940392]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.37940392]\n",
            "Token with lowest confidence: weather\n",
            "Prediction after iteration 0 : [4633] : ['weather'] : weather\n",
            "Probs after iteration 0: [0.37940392]\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [1996, 4633] : ['the', 'weather'] : the weather\n",
            "Initial probs: [0.34378797, 0.70701116]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.9642566, 0.70701116]\n",
            "Token with lowest confidence: weather\n",
            "Prediction after iteration 0 : [1996, 4633] : ['the', 'weather'] : the weather\n",
            "Probs after iteration 0: [0.9642566, 0.70701116]\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Initial prediction: [4586] : ['snow'] : snow\n",
            "Initial probs: [0.48303807]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.48303807]\n",
            "Token with lowest confidence: snow\n",
            "Prediction after iteration 0 : [4586] : ['snow'] : snow\n",
            "Probs after iteration 0: [0.48303807]\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [4586, 3785] : ['snow', 'conditions'] : snow conditions\n",
            "Initial probs: [0.1989496, 0.16776288]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.05951825, 0.16776288]\n",
            "Token with lowest confidence: snow\n",
            "Prediction after iteration 0 : [24706, 3785] : ['cloudy', 'conditions'] : cloudy conditions\n",
            "Probs after iteration 0: [0.15892208, 0.16776288]\n",
            "Iteration: 1\n",
            "Recomputed probs 1: [0.15892208, 0.20129476]\n",
            "Token with lowest confidence: cloudy\n",
            "Prediction after iteration 1 : [24706, 3785] : ['cloudy', 'conditions'] : cloudy conditions\n",
            "Probs after iteration 1: [0.15892208, 0.20129476]\n",
            "\u001b[1mConvergence reached in iteration 1!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Initial prediction: [2103] : ['city'] : city\n",
            "Initial probs: [0.13459142]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.13459142]\n",
            "Token with lowest confidence: city\n",
            "Prediction after iteration 0 : [2103] : ['city'] : city\n",
            "Probs after iteration 0: [0.13459142]\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [2334, 2381] : ['local', 'history'] : local history\n",
            "Initial probs: [0.04019448, 0.38753402]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.74839926, 0.38753402]\n",
            "Token with lowest confidence: history\n",
            "Prediction after iteration 0 : [2334, 2381] : ['local', 'history'] : local history\n",
            "Probs after iteration 0: [0.74839926, 0.38753402]\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Initial prediction: [4712] : ['promotion'] : promotion\n",
            "Initial probs: [0.11541903]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.11541903]\n",
            "Token with lowest confidence: promotion\n",
            "Prediction after iteration 0 : [4712] : ['promotion'] : promotion\n",
            "Probs after iteration 0: [0.11541903]\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [1996, 3105] : ['the', 'job'] : the job\n",
            "Initial probs: [0.30745187, 0.0642344]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.5701547, 0.0642344]\n",
            "Token with lowest confidence: job\n",
            "Prediction after iteration 0 : [1996, 3105] : ['the', 'job'] : the job\n",
            "Probs after iteration 0: [0.5701547, 0.0642344]\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Initial prediction: [12276] : ['dedication'] : dedication\n",
            "Initial probs: [0.18447323]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.18447323]\n",
            "Token with lowest confidence: dedication\n",
            "Prediction after iteration 0 : [12276] : ['dedication'] : dedication\n",
            "Probs after iteration 0: [0.18447323]\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [3167, 12276] : ['personal', 'dedication'] : personal dedication\n",
            "Initial probs: [0.04207264, 0.14212663]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.14925449, 0.14212663]\n",
            "Token with lowest confidence: dedication\n",
            "Prediction after iteration 0 : [3167, 12276] : ['personal', 'dedication'] : personal dedication\n",
            "Probs after iteration 0: [0.14925449, 0.14212663]\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [2010, 5541, 2943] : ['his', 'creative', 'energy'] : his creative energy\n",
            "Initial probs: [0.08862757, 0.06155125, 0.06635485]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.25953183, 0.30475864, 0.06635485]\n",
            "Token with lowest confidence: energy\n",
            "Prediction after iteration 0 : [2010, 5541, 2943] : ['his', 'creative', 'energy'] : his creative energy\n",
            "Probs after iteration 0: [0.25953183, 0.30475864, 0.06635485]\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Initial prediction: [17363] : ['scenery'] : scenery\n",
            "Initial probs: [0.27261895]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.27261895]\n",
            "Token with lowest confidence: scenery\n",
            "Prediction after iteration 0 : [17363] : ['scenery'] : scenery\n",
            "Probs after iteration 0: [0.27261895]\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [3059, 10833] : ['italian', 'countryside'] : italian countryside\n",
            "Initial probs: [0.2944674, 0.5196819]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.6819035, 0.5196819]\n",
            "Token with lowest confidence: countryside\n",
            "Prediction after iteration 0 : [3059, 10833] : ['italian', 'countryside'] : italian countryside\n",
            "Probs after iteration 0: [0.6819035, 0.5196819]\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [3059, 2406, 17363] : ['italian', 'country', 'scenery'] : italian country scenery\n",
            "Initial probs: [0.1806121, 0.077788845, 0.17598704]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.6640348, 0.13033812, 0.17598704]\n",
            "Token with lowest confidence: country\n",
            "Prediction after iteration 0 : [3059, 2406, 17363] : ['italian', 'country', 'scenery'] : italian country scenery\n",
            "Probs after iteration 0: [0.6640348, 0.13033812, 0.17598704]\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Initial prediction: [4253] : ['clothes'] : clothes\n",
            "Initial probs: [0.20658249]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.20658249]\n",
            "Token with lowest confidence: clothes\n",
            "Prediction after iteration 0 : [4253] : ['clothes'] : clothes\n",
            "Probs after iteration 0: [0.20658249]\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [5909, 2612] : ['fruit', 'instead'] : fruit instead\n",
            "Initial probs: [0.07742035, 0.45331413]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.089678906, 0.45331413]\n",
            "Token with lowest confidence: fruit\n",
            "Prediction after iteration 0 : [11546, 2612] : ['vegetables', 'instead'] : vegetables instead\n",
            "Probs after iteration 0: [0.20682354, 0.45331413]\n",
            "Iteration: 1\n",
            "Recomputed probs 1: [0.20682354, 0.42679006]\n",
            "Token with lowest confidence: vegetables\n",
            "Prediction after iteration 1 : [11546, 2612] : ['vegetables', 'instead'] : vegetables instead\n",
            "Probs after iteration 1: [0.20682354, 0.42679006]\n",
            "\u001b[1mConvergence reached in iteration 1!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [1010, 4840, 4253] : [',', 'fresh', 'clothes'] : , fresh clothes\n",
            "Initial probs: [0.17775607, 0.3296824, 0.45803368]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.97426, 0.046924155, 0.45803368]\n",
            "Token with lowest confidence: fresh\n",
            "Prediction after iteration 0 : [1010, 4550, 4253] : [',', 'clean', 'clothes'] : , clean clothes\n",
            "Probs after iteration 0: [0.97426, 0.49951717, 0.45803368]\n",
            "Iteration: 1\n",
            "Recomputed probs 1: [0.8296139, 0.49951717, 0.7175425]\n",
            "Token with lowest confidence: clean\n",
            "Prediction after iteration 1 : [1010, 4550, 4253] : [',', 'clean', 'clothes'] : , clean clothes\n",
            "Probs after iteration 1: [0.8296139, 0.49951717, 0.7175425]\n",
            "\u001b[1mConvergence reached in iteration 1!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [11546, 2005, 1996, 2154] : ['vegetables', 'for', 'the', 'day'] : vegetables for the day\n",
            "Initial probs: [0.08170625, 0.4296236, 0.64441377, 0.40310895]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.19818893, 0.9747308, 0.93066394, 0.40310895]\n",
            "Token with lowest confidence: vegetables\n",
            "Prediction after iteration 0 : [11546, 2005, 1996, 2154] : ['vegetables', 'for', 'the', 'day'] : vegetables for the day\n",
            "Probs after iteration 0: [0.19818893, 0.9747308, 0.93066394, 0.40310895]\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Initial prediction: [2168] : ['same'] : same\n",
            "Initial probs: [0.87108445]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.87108445]\n",
            "Token with lowest confidence: same\n",
            "Prediction after iteration 0 : [2168] : ['same'] : same\n",
            "Probs after iteration 0: [0.87108445]\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [2168, 2168] : ['same', 'same'] : same same\n",
            "Initial probs: [0.85934234, 0.07214218]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.13773672, 0.07214218]\n",
            "Token with lowest confidence: same\n",
            "Prediction after iteration 0 : [2168, 2168] : ['same', 'same'] : same same\n",
            "Probs after iteration 0: [0.13773672, 0.07214218]\n",
            "\u001b[1mConvergence reached in iteration 0!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [2230, 4386, 6042] : ['2010', 'olympic', 'qualifying'] : 2010 olympic qualifying\n",
            "Initial probs: [0.044758864, 0.10091909, 0.30796126]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.035062734, 0.9282432, 0.30796126]\n",
            "Token with lowest confidence: 2010\n",
            "Prediction after iteration 0 : [2355, 4386, 6042] : ['2016', 'olympic', 'qualifying'] : 2016 olympic qualifying\n",
            "Probs after iteration 0: [0.21645974, 0.9282432, 0.30796126]\n",
            "Iteration: 1\n",
            "Recomputed probs 1: [0.21645974, 0.9539358, 0.39803958]\n",
            "Token with lowest confidence: 2016\n",
            "Prediction after iteration 1 : [2355, 4386, 6042] : ['2016', 'olympic', 'qualifying'] : 2016 olympic qualifying\n",
            "Probs after iteration 1: [0.21645974, 0.9539358, 0.39803958]\n",
            "\u001b[1mConvergence reached in iteration 1!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "Initial prediction: [2286, 2621, 3783, 6042] : ['2013', 'summer', 'olympics', 'qualifying'] : 2013 summer olympics qualifying\n",
            "Initial probs: [0.07442033, 0.10485043, 0.97585326, 0.26702085]\n",
            "Iteration: 0\n",
            "Recomputed probs 0: [0.00040493088, 0.21162665, 0.8827625, 0.26702085]\n",
            "Token with lowest confidence: 2013\n",
            "Prediction after iteration 0 : [2262, 2621, 3783, 6042] : ['2012', 'summer', 'olympics', 'qualifying'] : 2012 summer olympics qualifying\n",
            "Probs after iteration 0: [0.296483, 0.21162665, 0.8827625, 0.26702085]\n",
            "Iteration: 1\n",
            "Recomputed probs 1: [0.296483, 0.94447064, 0.92132324, 0.30601686]\n",
            "Token with lowest confidence: 2012\n",
            "Prediction after iteration 1 : [2262, 2621, 3783, 6042] : ['2012', 'summer', 'olympics', 'qualifying'] : 2012 summer olympics qualifying\n",
            "Probs after iteration 1: [0.296483, 0.94447064, 0.92132324, 0.30601686]\n",
            "\u001b[1mConvergence reached in iteration 1!\u001b[0m\n",
            "-------------------------------------------------------\n",
            "------------------------------------------------------------------------------------------\n",
            "Paris is a [MASK] [MASK] to visit.\n",
            "[2173] : place : ['place']\n",
            "-------------------------------------------------------------------------\n",
            "Jupyter is the largest planet of the [MASK] [MASK].\n",
            "[5943, 2291] : solar system : ['solar', 'system']\n",
            "-------------------------------------------------------------------------\n",
            "The weather forecast predicts [MASK] [MASK] for tomorrow.\n",
            "[1996, 4633] : the weather : ['the', 'weather']\n",
            "-------------------------------------------------------------------------\n",
            "The weather forecast predicts heavy rain and [MASK] [MASK].\n",
            "[4586] : snow : ['snow']\n",
            "-------------------------------------------------------------------------\n",
            "He wanted to visit the museum and explore the [MASK] [MASK].\n",
            "[2334, 2381] : local history : ['local', 'history']\n",
            "-------------------------------------------------------------------------\n",
            "She was excited about the promotion and [MASK] [MASK].\n",
            "[1996, 3105] : the job : ['the', 'job']\n",
            "-------------------------------------------------------------------------\n",
            "He is known for his dedication and [MASK] [MASK] [MASK].\n",
            "[2010, 5541, 2943] : his creative energy : ['his', 'creative', 'energy']\n",
            "-------------------------------------------------------------------------\n",
            "They plan to travel to Italy and enjoy the beautiful [MASK] [MASK] [MASK].\n",
            "[3059, 10833] : italian countryside : ['italian', 'countryside']\n",
            "-------------------------------------------------------------------------\n",
            "She decided to go to the market and buy some fresh [MASK] [MASK] [MASK] [MASK].\n",
            "[1010, 4550, 4253] : , clean clothes : [',', 'clean', 'clothes']\n",
            "-------------------------------------------------------------------------\n",
            "He set a new world record at the [MASK] [MASK] [MASK] [MASK] event.\n",
            "[2168] : same : ['same']\n",
            "-------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conditional MLM\n",
        "# Beam search approach\n",
        "# Update: confidence based (confidence - average of predicted tokens probs)\n",
        "# restricted candidate_set_tokens added as parameter\n",
        "def fill_masks_beam_search(model_checkpoint: str, inputs: list[str], candidate_set_tokens=None, top_n=5, beam_width=5, verbose=0):\n",
        "\n",
        "    if top_n > beam_width:\n",
        "       raise ValueError(\"top_n must be less than or equal to beam_width\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "    model = TFAutoModelForMaskedLM.from_pretrained(model_checkpoint, from_pt=True)\n",
        "\n",
        "    mask_str = '[MASK]'\n",
        "    # Adjusting inputs for RoBERTa models\n",
        "    if 'roberta' in model_checkpoint:\n",
        "        mask_str = '<mask>'\n",
        "        inputs = [change_input_format(input) for input in inputs]\n",
        "\n",
        "    # model_max_length field not set by default for BioBERT and BioMedBERT models\n",
        "    if 'bio' in model_checkpoint.lower():\n",
        "        tokenizer.model_max_length = 512\n",
        "\n",
        "    if verbose:\n",
        "        print(f'Chosen model: {model_checkpoint}')\n",
        "        model.summary()\n",
        "\n",
        "    # if candidate_set_tokens is None, setting it to all tokens of the model\n",
        "    if candidate_set_tokens is None:\n",
        "      candidate_set_tokens = list(tokenizer.get_vocab().values()) # .keys() - decoded tokens (words/subwords)\n",
        "\n",
        "    all_outputs = []\n",
        "    all_outputs_decoded = []\n",
        "    for input in inputs:\n",
        "      # trying different mask token sequence lengths - from 1 to M (length of longest true answer)\n",
        "      M = input.count(mask_str)\n",
        "\n",
        "      max_confidence = 0\n",
        "      all_candidates = []\n",
        "\n",
        "      for i in range(1, M+1):\n",
        "        input_text = reduce_masks(input, i, mask_str)\n",
        "\n",
        "        tokenized_input = tokenizer(input_text, return_tensors=\"tf\")\n",
        "\n",
        "        # checking if the model uses token_type_ids (not used in RoBERTa models)\n",
        "        use_token_type_ids = 'token_type_ids' in tokenized_input\n",
        "\n",
        "        input_ids = tokenized_input[\"input_ids\"]\n",
        "\n",
        "        mask_token_indices = np.where(input_ids.numpy()[0] == tokenizer.mask_token_id)[0]\n",
        "\n",
        "        # Initializing the beam with the initial tokenized text (input_ids, attention_mask and token_type_ids (optional)) and a confidence of 0\n",
        "        beam = [(tokenized_input, 0.0)]\n",
        "\n",
        "        # Continue until all masks are filled\n",
        "        for mask_token_index in mask_token_indices:\n",
        "          candidates = []\n",
        "\n",
        "          for seq, confidence in beam:\n",
        "            token_logits = model(**seq).logits[0]\n",
        "            token_probs = tf.nn.softmax(token_logits, axis=-1)\n",
        "            mask_token_probs = token_probs[mask_token_index, :]\n",
        "\n",
        "            # getting logits of tokens that are present in a candidate set\n",
        "            mask_token_probs_candidates = tf.gather(mask_token_probs, candidate_set_tokens)\n",
        "\n",
        "            # tf.matf.top_k returns k top values and indices from the input tensor along last dimension (by default)\n",
        "            top_k_values, top_k_indices  = tf.math.top_k(mask_token_probs_candidates, k=beam_width)\n",
        "\n",
        "            # finding original indices (token ids):\n",
        "            # converting candidate_set_tokens to a tf tensor\n",
        "            candidate_set_tokens_tensor = tf.constant(candidate_set_tokens, dtype=tf.int32)\n",
        "\n",
        "            # using tf.gather to transform the indices to corresponding token ids from candidate_set_tokens_tensor\n",
        "            top_k_indices_original = tf.gather(candidate_set_tokens_tensor, top_k_indices)\n",
        "\n",
        "            for token_idx, token_prob in zip(top_k_indices_original, top_k_values):\n",
        "\n",
        "              # creating a new sequence with the predicted token\n",
        "              new_input_ids = tf.tensor_scatter_nd_update(seq['input_ids'], [[0, mask_token_index]], [token_idx])\n",
        "\n",
        "              if use_token_type_ids:\n",
        "                new_seq = {\n",
        "                    'input_ids': new_input_ids,\n",
        "                    'attention_mask': seq['attention_mask'],\n",
        "                    'token_type_ids': seq['token_type_ids']\n",
        "                }\n",
        "              else:\n",
        "                new_seq = {\n",
        "                    'input_ids': new_input_ids,\n",
        "                    'attention_mask': seq['attention_mask'],\n",
        "                }\n",
        "\n",
        "              # calculating the new confidence using probs\n",
        "              new_confidence = confidence + token_prob.numpy()\n",
        "\n",
        "              # adding the new sequence and its score to the candidates list\n",
        "              candidates.append((new_seq, new_confidence))\n",
        "\n",
        "          # selecting the top beam_width candidates (all candidates have mask sequences of same length - no need to divide confidence with i)\n",
        "          beam = heapq.nlargest(beam_width, candidates, key=lambda x: x[1])\n",
        "\n",
        "        # extracting top_n candidates sequences of the length i\n",
        "        top_n_candidates = heapq.nlargest(top_n, beam, key=lambda x: x[1])\n",
        "        # normalizing confidences - dividing with sequence length (i), adding length (i) to tuple\n",
        "        top_n_candidates = [(tokenized_input, confidence / i, i) for tokenized_input, confidence in top_n_candidates]\n",
        "\n",
        "        if verbose:\n",
        "          print(f'Candidates of a length {i}:')\n",
        "\n",
        "          for seq, confidence, i in top_n_candidates:\n",
        "            # prediction: from predicted token at the first to the predicted token at the last mask index (all mask tokens in a sequence)\n",
        "            prediction = seq['input_ids'].numpy()[0][mask_token_indices[0]:mask_token_indices[0]+i]\n",
        "            prediction_decoded = tokenizer.decode(prediction, skip_special_tokens=True)\n",
        "            print(f'Prediction: {prediction} : {tokenizer.convert_ids_to_tokens(prediction)} : {prediction_decoded}')\n",
        "            print(f'Confidence: {confidence}')\n",
        "          print('--------------------------------------------------------')\n",
        "\n",
        "        all_candidates += top_n_candidates\n",
        "\n",
        "      top_n_final_candidates = heapq.nlargest(top_n, all_candidates, key=lambda x: x[1])\n",
        "\n",
        "      if verbose:\n",
        "        print('\\033[1mFinal predictions:\\033[0m')\n",
        "\n",
        "      outputs = []\n",
        "      outputs_decoded = []\n",
        "\n",
        "      for seq, confidence, i in top_n_final_candidates:\n",
        "        prediction = seq['input_ids'].numpy()[0][mask_token_indices[0]:mask_token_indices[0]+i]\n",
        "        prediction_decoded = tokenizer.decode(prediction, skip_special_tokens=True)\n",
        "        outputs.append(list(prediction))\n",
        "        outputs.append(prediction_decoded)\n",
        "\n",
        "        if verbose:\n",
        "          print(f'Prediction: {prediction} : {tokenizer.convert_ids_to_tokens(prediction)} : {prediction_decoded}')\n",
        "          print(f'Confidence: {confidence}')\n",
        "\n",
        "      if verbose:\n",
        "        print('----------------------------------------------------------------------------------------------------')\n",
        "\n",
        "\n",
        "      all_outputs.append(outputs)\n",
        "      all_outputs_decoded.append(outputs_decoded)\n",
        "\n",
        "    return all_outputs, all_outputs_decoded"
      ],
      "metadata": {
        "id": "q-sbGhy3DlZe"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs, outputs_dec = fill_masks_beam_search(bert_models['BERT_base'], test_inputs, top_n=5, beam_width=5, verbose=1)\n",
        "\n",
        "#test_tokenizer = AutoTokenizer.from_pretrained(bert_models['BERT_base'])\n",
        "#i = 0\n",
        "#for output, output_dec in zip(outputs, outputs_dec):\n",
        "#  print(test_inputs[i])\n",
        "#  print(f\"{output} : {output_dec} : {test_tokenizer.convert_ids_to_tokens(output)}\")\n",
        "#  i += 1\n",
        "#  print('-------------------------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RITWX4JSDgOi",
        "outputId": "be4e9c3a-104b-4bb8-9405-329a90a95696"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen model: google-bert/bert-base-uncased\n",
            "Model: \"tf_bert_for_masked_lm_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  108891648 \n",
            "                                                                 \n",
            " mlm___cls (TFBertMLMHead)   multiple                  24459834  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109514298 (417.76 MB)\n",
            "Trainable params: 109514298 (417.76 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Candidates of a length 1:\n",
            "Prediction: [2173] : ['place'] : place\n",
            "Confidence: 0.7230950593948364\n",
            "Prediction: [2103] : ['city'] : city\n",
            "Confidence: 0.03346916660666466\n",
            "Prediction: [7688] : ['destination'] : destination\n",
            "Confidence: 0.026779673993587494\n",
            "Prediction: [5165] : ['pleasure'] : pleasure\n",
            "Confidence: 0.016575613990426064\n",
            "Prediction: [5440] : ['favorite'] : favorite\n",
            "Confidence: 0.015573428943753242\n",
            "--------------------------------------------------------\n",
            "Candidates of a length 2:\n",
            "Prediction: [2307 2173] : ['great', 'place'] : great place\n",
            "Confidence: 0.5600524544715881\n",
            "Prediction: [2204 2173] : ['good', 'place'] : good place\n",
            "Confidence: 0.49816809594631195\n",
            "Prediction: [4569 2173] : ['fun', 'place'] : fun place\n",
            "Confidence: 0.48314621299505234\n",
            "Prediction: [6919 2173] : ['wonderful', 'place'] : wonderful place\n",
            "Confidence: 0.48195110633969307\n",
            "Prediction: [5440 2103] : ['favorite', 'city'] : favorite city\n",
            "Confidence: 0.29121416062116623\n",
            "--------------------------------------------------------\n",
            "\u001b[1mFinal predictions:\u001b[0m\n",
            "Prediction: [2173] : ['place'] : place\n",
            "Confidence: 0.7230950593948364\n",
            "Prediction: [2307 2173] : ['great', 'place'] : great place\n",
            "Confidence: 0.5600524544715881\n",
            "Prediction: [2204 2173] : ['good', 'place'] : good place\n",
            "Confidence: 0.49816809594631195\n",
            "Prediction: [4569 2173] : ['fun', 'place'] : fun place\n",
            "Confidence: 0.48314621299505234\n",
            "Prediction: [6919 2173] : ['wonderful', 'place'] : wonderful place\n",
            "Confidence: 0.48195110633969307\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Candidates of a length 1:\n",
            "Prediction: [3103] : ['sun'] : sun\n",
            "Confidence: 0.20109564065933228\n",
            "Prediction: [2155] : ['family'] : family\n",
            "Confidence: 0.14977045357227325\n",
            "Prediction: [4231] : ['moon'] : moon\n",
            "Confidence: 0.11549866944551468\n",
            "Prediction: [2177] : ['group'] : group\n",
            "Confidence: 0.10975994914770126\n",
            "Prediction: [9324] : ['cluster'] : cluster\n",
            "Confidence: 0.10661657899618149\n",
            "--------------------------------------------------------\n",
            "Candidates of a length 2:\n",
            "Prediction: [5943 2291] : ['solar', 'system'] : solar system\n",
            "Confidence: 0.5188234094530344\n",
            "Prediction: [3103 2291] : ['sun', 'system'] : sun system\n",
            "Confidence: 0.3070455491542816\n",
            "Prediction: [ 4231 22834] : ['moon', 'io'] : moon io\n",
            "Confidence: 0.21072345227003098\n",
            "Prediction: [ 3103 13035] : ['sun', 'jupiter'] : sun jupiter\n",
            "Confidence: 0.18204675987362862\n",
            "Prediction: [ 2155 13035] : ['family', 'jupiter'] : family jupiter\n",
            "Confidence: 0.17832748591899872\n",
            "--------------------------------------------------------\n",
            "\u001b[1mFinal predictions:\u001b[0m\n",
            "Prediction: [5943 2291] : ['solar', 'system'] : solar system\n",
            "Confidence: 0.5188234094530344\n",
            "Prediction: [3103 2291] : ['sun', 'system'] : sun system\n",
            "Confidence: 0.3070455491542816\n",
            "Prediction: [ 4231 22834] : ['moon', 'io'] : moon io\n",
            "Confidence: 0.21072345227003098\n",
            "Prediction: [3103] : ['sun'] : sun\n",
            "Confidence: 0.20109564065933228\n",
            "Prediction: [ 3103 13035] : ['sun', 'jupiter'] : sun jupiter\n",
            "Confidence: 0.18204675987362862\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Candidates of a length 1:\n",
            "Prediction: [4633] : ['weather'] : weather\n",
            "Confidence: 0.3794039189815521\n",
            "Prediction: [3785] : ['conditions'] : conditions\n",
            "Confidence: 0.09965517371892929\n",
            "Prediction: [2824] : ['events'] : events\n",
            "Confidence: 0.05936749279499054\n",
            "Prediction: [7715] : ['temperatures'] : temperatures\n",
            "Confidence: 0.03451717644929886\n",
            "Prediction: [19939] : ['forecast'] : forecast\n",
            "Confidence: 0.023980941623449326\n",
            "--------------------------------------------------------\n",
            "Candidates of a length 2:\n",
            "Prediction: [1996 4633] : ['the', 'weather'] : the weather\n",
            "Confidence: 0.5253995656967163\n",
            "Prediction: [1037 4040] : ['a', 'storm'] : a storm\n",
            "Confidence: 0.43202754855155945\n",
            "Prediction: [4633 3785] : ['weather', 'conditions'] : weather conditions\n",
            "Confidence: 0.34403368830680847\n",
            "Prediction: [10173  4633] : ['predicted', 'weather'] : predicted weather\n",
            "Confidence: 0.3208392788656056\n",
            "Prediction: [ 1996 19939] : ['the', 'forecast'] : the forecast\n",
            "Confidence: 0.22790927067399025\n",
            "--------------------------------------------------------\n",
            "\u001b[1mFinal predictions:\u001b[0m\n",
            "Prediction: [1996 4633] : ['the', 'weather'] : the weather\n",
            "Confidence: 0.5253995656967163\n",
            "Prediction: [1037 4040] : ['a', 'storm'] : a storm\n",
            "Confidence: 0.43202754855155945\n",
            "Prediction: [4633] : ['weather'] : weather\n",
            "Confidence: 0.3794039189815521\n",
            "Prediction: [4633 3785] : ['weather', 'conditions'] : weather conditions\n",
            "Confidence: 0.34403368830680847\n",
            "Prediction: [10173  4633] : ['predicted', 'weather'] : predicted weather\n",
            "Confidence: 0.3208392788656056\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Candidates of a length 1:\n",
            "Prediction: [4586] : ['snow'] : snow\n",
            "Confidence: 0.483038067817688\n",
            "Prediction: [9451] : ['flooding'] : flooding\n",
            "Confidence: 0.12270496040582657\n",
            "Prediction: [26043] : ['snowfall'] : snowfall\n",
            "Confidence: 0.07722530514001846\n",
            "Prediction: [16889] : ['hail'] : hail\n",
            "Confidence: 0.06607729941606522\n",
            "Prediction: [7266] : ['winds'] : winds\n",
            "Confidence: 0.05122636258602142\n",
            "--------------------------------------------------------\n",
            "Candidates of a length 2:\n",
            "Prediction: [3082 7266] : ['heavy', 'winds'] : heavy winds\n",
            "Confidence: 0.24553800001740456\n",
            "Prediction: [5729 7266] : ['severe', 'winds'] : severe winds\n",
            "Confidence: 0.22080331575125456\n",
            "Prediction: [4586 3785] : ['snow', 'conditions'] : snow conditions\n",
            "Confidence: 0.18335624039173126\n",
            "Prediction: [ 4586 12642] : ['snow', 'storms'] : snow storms\n",
            "Confidence: 0.1759142056107521\n",
            "Prediction: [ 2422 26043] : ['light', 'snowfall'] : light snowfall\n",
            "Confidence: 0.17567956075072289\n",
            "--------------------------------------------------------\n",
            "\u001b[1mFinal predictions:\u001b[0m\n",
            "Prediction: [4586] : ['snow'] : snow\n",
            "Confidence: 0.483038067817688\n",
            "Prediction: [3082 7266] : ['heavy', 'winds'] : heavy winds\n",
            "Confidence: 0.24553800001740456\n",
            "Prediction: [5729 7266] : ['severe', 'winds'] : severe winds\n",
            "Confidence: 0.22080331575125456\n",
            "Prediction: [4586 3785] : ['snow', 'conditions'] : snow conditions\n",
            "Confidence: 0.18335624039173126\n",
            "Prediction: [ 4586 12642] : ['snow', 'storms'] : snow storms\n",
            "Confidence: 0.1759142056107521\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Candidates of a length 1:\n",
            "Prediction: [2103] : ['city'] : city\n",
            "Confidence: 0.13459141552448273\n",
            "Prediction: [5286] : ['grounds'] : grounds\n",
            "Confidence: 0.058149199932813644\n",
            "Prediction: [2088] : ['world'] : world\n",
            "Confidence: 0.05197950825095177\n",
            "Prediction: [5822] : ['gardens'] : gardens\n",
            "Confidence: 0.04061656445264816\n",
            "Prediction: [2381] : ['history'] : history\n",
            "Confidence: 0.03510591387748718\n",
            "--------------------------------------------------------\n",
            "Candidates of a length 2:\n",
            "Prediction: [2396 2088] : ['art', 'world'] : art world\n",
            "Confidence: 0.29854012094438076\n",
            "Prediction: [3019 2088] : ['natural', 'world'] : natural world\n",
            "Confidence: 0.2893369998782873\n",
            "Prediction: [2334 2381] : ['local', 'history'] : local history\n",
            "Confidence: 0.2138642519712448\n",
            "Prediction: [ 4193 10833] : ['surrounding', 'countryside'] : surrounding countryside\n",
            "Confidence: 0.1410056296736002\n",
            "Prediction: [4193 2181] : ['surrounding', 'area'] : surrounding area\n",
            "Confidence: 0.12280298210680485\n",
            "--------------------------------------------------------\n",
            "\u001b[1mFinal predictions:\u001b[0m\n",
            "Prediction: [2396 2088] : ['art', 'world'] : art world\n",
            "Confidence: 0.29854012094438076\n",
            "Prediction: [3019 2088] : ['natural', 'world'] : natural world\n",
            "Confidence: 0.2893369998782873\n",
            "Prediction: [2334 2381] : ['local', 'history'] : local history\n",
            "Confidence: 0.2138642519712448\n",
            "Prediction: [ 4193 10833] : ['surrounding', 'countryside'] : surrounding countryside\n",
            "Confidence: 0.1410056296736002\n",
            "Prediction: [2103] : ['city'] : city\n",
            "Confidence: 0.13459141552448273\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Candidates of a length 1:\n",
            "Prediction: [4712] : ['promotion'] : promotion\n",
            "Confidence: 0.11541903018951416\n",
            "Prediction: [11845] : ['publicity'] : publicity\n",
            "Confidence: 0.024708831682801247\n",
            "Prediction: [3112] : ['success'] : success\n",
            "Confidence: 0.019562313333153725\n",
            "Prediction: [4935] : ['expansion'] : expansion\n",
            "Confidence: 0.019142895936965942\n",
            "Prediction: [2778] : ['tour'] : tour\n",
            "Confidence: 0.01587841287255287\n",
            "--------------------------------------------------------\n",
            "Candidates of a length 2:\n",
            "Prediction: [1996 3105] : ['the', 'job'] : the job\n",
            "Confidence: 0.18584313616156578\n",
            "Prediction: [1996 4712] : ['the', 'promotion'] : the promotion\n",
            "Confidence: 0.17431610077619553\n",
            "Prediction: [1996 2769] : ['the', 'money'] : the money\n",
            "Confidence: 0.16517460905015469\n",
            "Prediction: [ 1996 11845] : ['the', 'publicity'] : the publicity\n",
            "Confidence: 0.16461550071835518\n",
            "Prediction: [1996 2778] : ['the', 'tour'] : the tour\n",
            "Confidence: 0.16446528211236\n",
            "--------------------------------------------------------\n",
            "\u001b[1mFinal predictions:\u001b[0m\n",
            "Prediction: [1996 3105] : ['the', 'job'] : the job\n",
            "Confidence: 0.18584313616156578\n",
            "Prediction: [1996 4712] : ['the', 'promotion'] : the promotion\n",
            "Confidence: 0.17431610077619553\n",
            "Prediction: [1996 2769] : ['the', 'money'] : the money\n",
            "Confidence: 0.16517460905015469\n",
            "Prediction: [ 1996 11845] : ['the', 'publicity'] : the publicity\n",
            "Confidence: 0.16461550071835518\n",
            "Prediction: [1996 2778] : ['the', 'tour'] : the tour\n",
            "Confidence: 0.16446528211236\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Candidates of a length 1:\n",
            "Prediction: [12276] : ['dedication'] : dedication\n",
            "Confidence: 0.18447323143482208\n",
            "Prediction: [4105] : ['leadership'] : leadership\n",
            "Confidence: 0.07356525212526321\n",
            "Prediction: [9128] : ['determination'] : determination\n",
            "Confidence: 0.06479177623987198\n",
            "Prediction: [8424] : ['courage'] : courage\n",
            "Confidence: 0.048974841833114624\n",
            "Prediction: [26161] : ['generosity'] : generosity\n",
            "Confidence: 0.04459388926625252\n",
            "--------------------------------------------------------\n",
            "Candidates of a length 2:\n",
            "Prediction: [2658 2964] : ['professional', '##ism'] : professionalism\n",
            "Confidence: 0.4801727468147874\n",
            "Prediction: [3893 7729] : ['positive', 'attitude'] : positive attitude\n",
            "Confidence: 0.17227263282984495\n",
            "Prediction: [ 3167 12276] : ['personal', 'dedication'] : personal dedication\n",
            "Confidence: 0.0920996367931366\n",
            "Prediction: [3893 6180] : ['positive', 'personality'] : positive personality\n",
            "Confidence: 0.06898366194218397\n",
            "Prediction: [3167 8426] : ['personal', 'commitment'] : personal commitment\n",
            "Confidence: 0.060336530208587646\n",
            "--------------------------------------------------------\n",
            "Candidates of a length 3:\n",
            "Prediction: [ 2152  3167 19593] : ['high', 'personal', 'esteem'] : high personal esteem\n",
            "Confidence: 0.1619025096297264\n",
            "Prediction: [2204 3167 2166] : ['good', 'personal', 'life'] : good personal life\n",
            "Confidence: 0.14750926569104195\n",
            "Prediction: [2152 6832 2504] : ['high', 'emotional', 'level'] : high emotional level\n",
            "Confidence: 0.12490297108888626\n",
            "Prediction: [2152 3167 5300] : ['high', 'personal', 'values'] : high personal values\n",
            "Confidence: 0.12045515328645706\n",
            "Prediction: [2152 6832 3798] : ['high', 'emotional', 'levels'] : high emotional levels\n",
            "Confidence: 0.1027692382534345\n",
            "--------------------------------------------------------\n",
            "\u001b[1mFinal predictions:\u001b[0m\n",
            "Prediction: [2658 2964] : ['professional', '##ism'] : professionalism\n",
            "Confidence: 0.4801727468147874\n",
            "Prediction: [12276] : ['dedication'] : dedication\n",
            "Confidence: 0.18447323143482208\n",
            "Prediction: [3893 7729] : ['positive', 'attitude'] : positive attitude\n",
            "Confidence: 0.17227263282984495\n",
            "Prediction: [ 2152  3167 19593] : ['high', 'personal', 'esteem'] : high personal esteem\n",
            "Confidence: 0.1619025096297264\n",
            "Prediction: [2204 3167 2166] : ['good', 'personal', 'life'] : good personal life\n",
            "Confidence: 0.14750926569104195\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Candidates of a length 1:\n",
            "Prediction: [17363] : ['scenery'] : scenery\n",
            "Confidence: 0.27261894941329956\n",
            "Prediction: [10833] : ['countryside'] : countryside\n",
            "Confidence: 0.23737192153930664\n",
            "Prediction: [2406] : ['country'] : country\n",
            "Confidence: 0.10373038053512573\n",
            "Prediction: [2103] : ['city'] : city\n",
            "Confidence: 0.03828267753124237\n",
            "Prediction: [4020] : ['mountains'] : mountains\n",
            "Confidence: 0.032152872532606125\n",
            "--------------------------------------------------------\n",
            "Candidates of a length 2:\n",
            "Prediction: [ 3059 10833] : ['italian', 'countryside'] : italian countryside\n",
            "Confidence: 0.40707463026046753\n",
            "Prediction: [23322 10833] : ['tuscany', 'countryside'] : tuscany countryside\n",
            "Confidence: 0.20801755972206593\n",
            "Prediction: [ 3059 17363] : ['italian', 'scenery'] : italian scenery\n",
            "Confidence: 0.1775427982211113\n",
            "Prediction: [10553 10833] : ['naples', 'countryside'] : naples countryside\n",
            "Confidence: 0.176925927400589\n",
            "Prediction: [3059 2406] : ['italian', 'country'] : italian country\n",
            "Confidence: 0.17245207354426384\n",
            "--------------------------------------------------------\n",
            "Candidates of a length 3:\n",
            "Prediction: [23322  1998 10553] : ['tuscany', 'and', 'naples'] : tuscany and naples\n",
            "Confidence: 0.2701706358542045\n",
            "Prediction: [23322  1998 23322] : ['tuscany', 'and', 'tuscany'] : tuscany and tuscany\n",
            "Confidence: 0.22867745347321033\n",
            "Prediction: [23322  1998  3304] : ['tuscany', 'and', 'italy'] : tuscany and italy\n",
            "Confidence: 0.21586569833258787\n",
            "Prediction: [23322  1998  7701] : ['tuscany', 'and', 'florence'] : tuscany and florence\n",
            "Confidence: 0.21270343599220118\n",
            "Prediction: [23322  1998 12071] : ['tuscany', 'and', 'sicily'] : tuscany and sicily\n",
            "Confidence: 0.2109627928584814\n",
            "--------------------------------------------------------\n",
            "\u001b[1mFinal predictions:\u001b[0m\n",
            "Prediction: [ 3059 10833] : ['italian', 'countryside'] : italian countryside\n",
            "Confidence: 0.40707463026046753\n",
            "Prediction: [17363] : ['scenery'] : scenery\n",
            "Confidence: 0.27261894941329956\n",
            "Prediction: [23322  1998 10553] : ['tuscany', 'and', 'naples'] : tuscany and naples\n",
            "Confidence: 0.2701706358542045\n",
            "Prediction: [10833] : ['countryside'] : countryside\n",
            "Confidence: 0.23737192153930664\n",
            "Prediction: [23322  1998 23322] : ['tuscany', 'and', 'tuscany'] : tuscany and tuscany\n",
            "Confidence: 0.22867745347321033\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Candidates of a length 1:\n",
            "Prediction: [4253] : ['clothes'] : clothes\n",
            "Confidence: 0.20658248662948608\n",
            "Prediction: [11546] : ['vegetables'] : vegetables\n",
            "Confidence: 0.18814626336097717\n",
            "Prediction: [3965] : ['produce'] : produce\n",
            "Confidence: 0.1469021886587143\n",
            "Prediction: [5909] : ['fruit'] : fruit\n",
            "Confidence: 0.0690375417470932\n",
            "Prediction: [7852] : ['bread'] : bread\n",
            "Confidence: 0.048005878925323486\n",
            "--------------------------------------------------------\n",
            "Candidates of a length 2:\n",
            "Prediction: [17776  7852] : ['baked', 'bread'] : baked bread\n",
            "Confidence: 0.4007808417081833\n",
            "Prediction: [5909 2612] : ['fruit', 'instead'] : fruit instead\n",
            "Confidence: 0.2653672359883785\n",
            "Prediction: [4840 4253] : ['fresh', 'clothes'] : fresh clothes\n",
            "Confidence: 0.1316994782537222\n",
            "Prediction: [4157 2612] : ['coffee', 'instead'] : coffee instead\n",
            "Confidence: 0.12602746486663818\n",
            "Prediction: [4840 3965] : ['fresh', 'produce'] : fresh produce\n",
            "Confidence: 0.11982392333447933\n",
            "--------------------------------------------------------\n",
            "Candidates of a length 3:\n",
            "Prediction: [ 1011 17776  7852] : ['-', 'baked', 'bread'] : - baked bread\n",
            "Confidence: 0.41901178906361264\n",
            "Prediction: [17776 17776  5350] : ['baked', 'baked', 'goods'] : baked baked goods\n",
            "Confidence: 0.34415940567851067\n",
            "Prediction: [1010 4840 4253] : [',', 'fresh', 'clothes'] : , fresh clothes\n",
            "Confidence: 0.321824053923289\n",
            "Prediction: [1998 4840 4253] : ['and', 'fresh', 'clothes'] : and fresh clothes\n",
            "Confidence: 0.2762698431809743\n",
            "Prediction: [1998 4840 3965] : ['and', 'fresh', 'produce'] : and fresh produce\n",
            "Confidence: 0.19647864003976187\n",
            "--------------------------------------------------------\n",
            "Candidates of a length 4:\n",
            "Prediction: [11546  2005  1996  2154] : ['vegetables', 'for', 'the', 'day'] : vegetables for the day\n",
            "Confidence: 0.38971314392983913\n",
            "Prediction: [7852 2005 1996 2154] : ['bread', 'for', 'the', 'day'] : bread for the day\n",
            "Confidence: 0.36205734591931105\n",
            "Prediction: [11546  2005  1996  3006] : ['vegetables', 'for', 'the', 'market'] : vegetables for the market\n",
            "Confidence: 0.3048566859215498\n",
            "Prediction: [11546  2005  1996  3944] : ['vegetables', 'for', 'the', 'evening'] : vegetables for the evening\n",
            "Confidence: 0.3021548129618168\n",
            "Prediction: [11546  2005  1996  2305] : ['vegetables', 'for', 'the', 'night'] : vegetables for the night\n",
            "Confidence: 0.2993728667497635\n",
            "--------------------------------------------------------\n",
            "\u001b[1mFinal predictions:\u001b[0m\n",
            "Prediction: [ 1011 17776  7852] : ['-', 'baked', 'bread'] : - baked bread\n",
            "Confidence: 0.41901178906361264\n",
            "Prediction: [17776  7852] : ['baked', 'bread'] : baked bread\n",
            "Confidence: 0.4007808417081833\n",
            "Prediction: [11546  2005  1996  2154] : ['vegetables', 'for', 'the', 'day'] : vegetables for the day\n",
            "Confidence: 0.38971314392983913\n",
            "Prediction: [7852 2005 1996 2154] : ['bread', 'for', 'the', 'day'] : bread for the day\n",
            "Confidence: 0.36205734591931105\n",
            "Prediction: [17776 17776  5350] : ['baked', 'baked', 'goods'] : baked baked goods\n",
            "Confidence: 0.34415940567851067\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Candidates of a length 1:\n",
            "Prediction: [2168] : ['same'] : same\n",
            "Confidence: 0.871084451675415\n",
            "Prediction: [3732] : ['latter'] : latter\n",
            "Confidence: 0.03491456061601639\n",
            "Prediction: [3265] : ['individual'] : individual\n",
            "Confidence: 0.003208558540791273\n",
            "Prediction: [2355] : ['2016'] : 2016\n",
            "Confidence: 0.002884921384975314\n",
            "Prediction: [2230] : ['2010'] : 2010\n",
            "Confidence: 0.0027621560730040073\n",
            "--------------------------------------------------------\n",
            "Candidates of a length 2:\n",
            "Prediction: [2168 2168] : ['same', 'same'] : same same\n",
            "Confidence: 0.4657422564923763\n",
            "Prediction: [2168 6482] : ['same', 'athletics'] : same athletics\n",
            "Confidence: 0.4600248448550701\n",
            "Prediction: [2168 9043] : ['same', 'sprint'] : same sprint\n",
            "Confidence: 0.4582518842071295\n",
            "Prediction: [2168 3265] : ['same', 'individual'] : same individual\n",
            "Confidence: 0.4524913653731346\n",
            "Prediction: [2168 4386] : ['same', 'olympic'] : same olympic\n",
            "Confidence: 0.4485635794699192\n",
            "--------------------------------------------------------\n",
            "Candidates of a length 3:\n",
            "Prediction: [2286 5972 6482] : ['2013', 'masters', 'athletics'] : 2013 masters athletics\n",
            "Confidence: 0.23141860837737718\n",
            "Prediction: [2268 5972 6482] : ['2009', 'masters', 'athletics'] : 2009 masters athletics\n",
            "Confidence: 0.20217431833346686\n",
            "Prediction: [2262 4386 6042] : ['2012', 'olympic', 'qualifying'] : 2012 olympic qualifying\n",
            "Confidence: 0.15864547652502856\n",
            "Prediction: [2230 4386 6042] : ['2010', 'olympic', 'qualifying'] : 2010 olympic qualifying\n",
            "Confidence: 0.15121306975682577\n",
            "Prediction: [2268 5972 2186] : ['2009', 'masters', 'series'] : 2009 masters series\n",
            "Confidence: 0.14406898866097131\n",
            "--------------------------------------------------------\n",
            "Candidates of a length 4:\n",
            "Prediction: [2230 2621 3783 6042] : ['2010', 'summer', 'olympics', 'qualifying'] : 2010 summer olympics qualifying\n",
            "Confidence: 0.3763874676078558\n",
            "Prediction: [2262 2621 3783 6042] : ['2012', 'summer', 'olympics', 'qualifying'] : 2012 summer olympics qualifying\n",
            "Confidence: 0.3743621502071619\n",
            "Prediction: [2325 2621 3783 6042] : ['2015', 'summer', 'olympics', 'qualifying'] : 2015 summer olympics qualifying\n",
            "Confidence: 0.37161353789269924\n",
            "Prediction: [2286 2621 3783 6042] : ['2013', 'summer', 'olympics', 'qualifying'] : 2013 summer olympics qualifying\n",
            "Confidence: 0.35553621873259544\n",
            "Prediction: [2262 2621 3783 8263] : ['2012', 'summer', 'olympics', 'qualification'] : 2012 summer olympics qualification\n",
            "Confidence: 0.32378844916820526\n",
            "--------------------------------------------------------\n",
            "\u001b[1mFinal predictions:\u001b[0m\n",
            "Prediction: [2168] : ['same'] : same\n",
            "Confidence: 0.871084451675415\n",
            "Prediction: [2168 2168] : ['same', 'same'] : same same\n",
            "Confidence: 0.4657422564923763\n",
            "Prediction: [2168 6482] : ['same', 'athletics'] : same athletics\n",
            "Confidence: 0.4600248448550701\n",
            "Prediction: [2168 9043] : ['same', 'sprint'] : same sprint\n",
            "Confidence: 0.4582518842071295\n",
            "Prediction: [2168 3265] : ['same', 'individual'] : same individual\n",
            "Confidence: 0.4524913653731346\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# uncased\n",
        "bert_models = {'BERT_base' : \"google-bert/bert-base-uncased\", 'BERT_large': \"google-bert/bert-large-uncased\",\n",
        "                'BERT_large_wwm': \"google-bert/bert-large-uncased-whole-word-masking\"}\n",
        "# cased\n",
        "roberta_models = {'RoBERTa_base': \"FacebookAI/roberta-base\", 'RoBERTa_large': \"FacebookAI/roberta-large\"}\n",
        "# uncased\n",
        "albert_models = {'ALBERT_base': \"albert/albert-base-v2\", 'ALBERT_xxlarge': \"albert/albert-xxlarge-v2\"}\n",
        "# cased\n",
        "biobert_models = {'BioBERT': \"dmis-lab/biobert-base-cased-v1.2\"}\n",
        "# uncased\n",
        "biomedbert_models = {'BioMedBERT_base_abstract' : \"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract\",\n",
        "                     'BioMedBERT_base_full': \"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\",\n",
        "                     'BioMedBERT_large_abstract': \"microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract\"}"
      ],
      "metadata": {
        "id": "cu86AmMdvPHM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DPmI6_KCc7c_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9H_BLL-sc6yj"
      }
    }
  ]
}